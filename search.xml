<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Ubuntu 重設 root 密碼</title>
      <link href="2021/10/13/ubuntu-reset-password/"/>
      <url>2021/10/13/ubuntu-reset-password/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如果開機發生硬碟故障或是不可預期的錯誤時，就會需要root密碼進入recovery mode，然而如果當初沒設root密碼或是忘記密碼，就會無法進入介面操作，這個時候就會需要重設root密碼。</p><hr><h2 id="解決方法"><a href="#解決方法" class="headerlink" title="解決方法"></a>解決方法</h2><p>開機後進入 GRUB 選單，按 <code>e</code> 編輯，在 linux 那行的尾端填入以下指令，最後用 Crtl+x 或 F10 開機。<br>原本為 <code>ro ......</code>，請將<code>ro</code>後面整串替換成 <code>rw init=/bin/bash</code></p><img src= "/img/loading.gif" data-src="/2021/10/13/ubuntu-reset-password/grub.png" class="" title="進入 grub 畫面"><p>進入系統修改密碼後，重開機即可使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">passwd root</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UBUNTU </tag>
            
            <tag> PASSWORD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NVIDIA DALI 加速資料載入及處理</title>
      <link href="2021/06/08/nvidia-dali/"/>
      <url>2021/06/08/nvidia-dali/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Some things in life are worth waiting for.</p><footer><strong>Danielle Steel</strong><cite>Secrets</cite></footer></blockquote><hr>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> TRAIN </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton 模型壓力測試</title>
      <link href="2021/05/22/nvidia-triton-model-analyzer/"/>
      <url>2021/05/22/nvidia-triton-model-analyzer/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Some things in life are worth waiting for.</p><footer><strong>Danielle Steel</strong><cite>Secrets</cite></footer></blockquote><hr>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Inference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton 分類推論輸出轉成可讀性類別名稱</title>
      <link href="2021/05/22/nvidia-triton-label/"/>
      <url>2021/05/22/nvidia-triton-label/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>分類模型輸出如果要轉成人類可讀性的文字類別，在 Triton Server 端模型庫中添加類別名稱文件即可，本篇將舉 <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener">Fashion MNIST</a> 為例。<br>詳細 Triton Inference Server 的功能可參考此<a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/">文章</a>。</p><hr><h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><p>系統環境</p><ul><li>OS：Ubuntu 20.04</li><li>GPU Driver：450.119.04</li><li>Docker：19.03.14</li><li>Docker Image：nvcr.io/nvidia/tritonserver:21.05-py3</li></ul><h4 id="訓練模型"><a href="#訓練模型" class="headerlink" title="訓練模型"></a>訓練模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">train_images = train_images / <span class="number">255.0</span></span><br><span class="line">test_images = test_images / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model.save(<span class="string">'model.savedmodel'</span>)</span><br></pre></td></tr></table></figure><h4 id="編輯設定檔"><a href="#編輯設定檔" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"fashion"</span></span><br><span class="line">platform: <span class="string">"tensorflow_savedmodel"</span></span><br><span class="line">max_batch_size: <span class="number">32</span></span><br><span class="line">input [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"flatten_input"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [<span class="number">28</span>, <span class="number">28</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">output [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"dense_1"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [<span class="number">10</span>]</span><br><span class="line">        label_filename: <span class="string">"labels.txt"</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">instance_group [</span><br><span class="line">    &#123;</span><br><span class="line">        kind: KIND_GPU</span><br><span class="line">        count: <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">optimization &#123; execution_accelerators &#123;</span><br><span class="line">    gpu_execution_accelerator : [ &#123;</span><br><span class="line">        name : <span class="string">"tensorrt"</span></span><br><span class="line">        parameters &#123; key: <span class="string">"precision_mode"</span> value: <span class="string">"FP16"</span> &#125;&#125;]</span><br><span class="line">&#125;&#125;</span><br><span class="line"></span><br><span class="line">version_policy &#123; latest &#123; num_versions: <span class="number">1</span> &#125; &#125;</span><br><span class="line"></span><br><span class="line">dynamic_batching &#123;</span><br><span class="line">  preferred_batch_size: [ <span class="number">4</span>, <span class="number">8</span> ]</span><br><span class="line">  max_queue_delay_microseconds: <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="編輯類別名稱檔"><a href="#編輯類別名稱檔" class="headerlink" title="編輯類別名稱檔"></a>編輯類別名稱檔</h4><p>檔名要跟模型設定檔裡面設的一樣，如此範例設為 <code>labels.txt</code><br>請依照當初訓練時，分類的順序依序填入</p><img src= "/img/loading.gif" data-src="/2021/05/22/nvidia-triton-label/label.PNG" class="" title="對照圖"><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">T-shirt&#x2F;top</span><br><span class="line">Trouser</span><br><span class="line">Pullover</span><br><span class="line">Dress</span><br><span class="line">Coat</span><br><span class="line">Sandal</span><br><span class="line">Shirt</span><br><span class="line">Sneaker</span><br><span class="line">Bag</span><br><span class="line">Ankle boot</span><br></pre></td></tr></table></figure><h4 id="建立模型庫"><a href="#建立模型庫" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>檔案架構如下圖</p><img src= "/img/loading.gif" data-src="/2021/05/22/nvidia-triton-label/tree.PNG" class="" title="檔案架構圖"><h4 id="運行伺服器端"><a href="#運行伺服器端" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus all --name Triton_Server --shm-size&#x3D;1g --ulimit memlock&#x3D;-1 --ulimit stack&#x3D;67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v &#x2F;home&#x2F;user&#x2F;Documents&#x2F;models:&#x2F;models nvcr.io&#x2F;nvidia&#x2F;tritonserver:21.05-py3 tritonserver --model-store&#x3D;&#x2F;models</span><br></pre></td></tr></table></figure><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><p>系統環境</p><ul><li>OS：Ubuntu 20.04</li><li>GPU Driver：450.119.04</li><li>Docker：19.03.14</li><li>Docker Image：nvcr.io/nvidia/tritonserver:21.05-py3-sdk</li></ul><h4 id="撰寫程式碼"><a href="#撰寫程式碼" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tritonclient.grpc <span class="keyword">as</span> grpcclient</span><br><span class="line"><span class="keyword">from</span> tritonclient.utils <span class="keyword">import</span> triton_to_np_dtype</span><br><span class="line"><span class="keyword">from</span> tritonclient <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="comment">## 前處理</span></span><br><span class="line">img = Image.open(<span class="string">'input.JPG'</span>).convert(<span class="string">'L'</span>)</span><br><span class="line">img = img.resize((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">imgArr = np.asarray(img)/<span class="number">255</span></span><br><span class="line">imgArr = np.expand_dims(imgArr, axis=<span class="number">0</span>)</span><br><span class="line">imgArr= imgArr.astype(triton_to_np_dtype(<span class="string">'FP32'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Client-Server 溝通</span></span><br><span class="line">triton_client = grpcclient.InferenceServerClient(url=<span class="string">'localhost:8001'</span>, verbose=<span class="number">0</span>)</span><br><span class="line">inputs = []</span><br><span class="line">inputs.append(grpcclient.InferInput(<span class="string">'flatten_input'</span>, imgArr.shape, <span class="string">'FP32'</span>))</span><br><span class="line">inputs[<span class="number">0</span>].set_data_from_numpy(imgArr)</span><br><span class="line">outputs = []</span><br><span class="line">outputs.append(grpcclient.InferRequestedOutput(<span class="string">'dense_1'</span>,class_count=<span class="number">10</span>))</span><br><span class="line">responses = []</span><br><span class="line">responses.append(triton_client.infer(<span class="string">'fashion'</span>,inputs,</span><br><span class="line">                    request_id=str(<span class="number">1</span>),</span><br><span class="line">                    model_version=<span class="string">'1'</span>,</span><br><span class="line">                    outputs=outputs))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 後處理</span></span><br><span class="line"><span class="keyword">print</span> (responses[<span class="number">0</span>].as_numpy(<span class="string">"dense_1"</span>)[<span class="number">0</span>][<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h4 id="運行客戶端"><a href="#運行客戶端" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --name Triton_Client -v &#x2F;home&#x2F;user&#x2F;data:&#x2F;data nvcr.io&#x2F;nvidia&#x2F;tritonserver:21.05-py3-sdk bash -c &#39;python &#x2F;data&#x2F;client.py&#39;</span><br></pre></td></tr></table></figure><p>欲推論的圖片</p><img src= "/img/loading.gif" data-src="/2021/05/22/nvidia-triton-label/input.PNG" class="" title="推論圖片"><p>輸出結果</p><p>意義為 (模型輸出數值):(標籤):(類別名稱)</p><img src= "/img/loading.gif" data-src="/2021/05/22/nvidia-triton-label/output.PNG" class="" title="輸出結果">]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Inference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>透過 MIG-PARTED 管理 MIG</title>
      <link href="2021/05/22/nvidia-mig-parted/"/>
      <url>2021/05/22/nvidia-mig-parted/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Multi-Instance GPU (MIG) 是安培世代中新出的操作模式，允許使用者能安全的對 GPU 切分多個 GPU 實例出來。<br>而 MIG-PARTED 是能讓管理者方便管理 MIG 的工具，透過 yaml 格式定義多組 MIG 組態，在運行系統時，指定組態即可快速的啟用配置，另外也可透過同一份 yaml 去佈署在所有的節點上。</p><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>設定檔以 yaml 格式撰寫，以下就直接透過範例說明</p><p>以此為例，我總共定義了兩個組態 <code>all-1g.10gb</code> 及 <code>custom-config</code><br><code>all-1g.10gb</code> 情境為除了PCIE-ID 0x20B210DE 的 GPU 不要設定之外，要在每個 GPU 上都切出 7 個 1g.10gb</p><p><code>custom-config</code> 情境為<br>GPU編號0跟1要切出3個2g.20gb及1個1g.10gb<br>GPU編號2要切出2個3g.40gb<br>GPU編號4不啟用MIG</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">mig-configs:</span></span><br><span class="line">  <span class="attr">all-1g.10gb:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">device-filter:</span> <span class="string">"0x20B210DE"</span></span><br><span class="line">      <span class="attr">devices:</span> <span class="string">all</span></span><br><span class="line">      <span class="attr">mig-enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">mig-devices:</span></span><br><span class="line">        <span class="attr">"1g.10gb":</span> <span class="number">7</span></span><br><span class="line">  </span><br><span class="line">  <span class="attr">custom-config:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">devices:</span> <span class="string">[0,1]</span></span><br><span class="line">      <span class="attr">mig-enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">mig-devices:</span></span><br><span class="line">        <span class="attr">"2g.20gb":</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">"1g.10gb":</span> <span class="number">1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">devices:</span> <span class="string">[2]</span></span><br><span class="line">      <span class="attr">mig-enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">mig-devices:</span></span><br><span class="line">        <span class="attr">"3g.40gb":</span> <span class="number">2</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">devices:</span> <span class="string">[4]</span></span><br><span class="line">      <span class="attr">mig-enabled:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">mig-devices:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><hr><h2 id="安裝與執行"><a href="#安裝與執行" class="headerlink" title="安裝與執行"></a>安裝與執行</h2><p>下載 github 並建構 <code>nvidia-mig-parted</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone http:&#x2F;&#x2F;github.com&#x2F;NVIDIA&#x2F;mig-parted -b v0.1.3</span><br><span class="line">cd mig-parted</span><br><span class="line">go build .&#x2F;cmd&#x2F;nvidia-mig-parted</span><br></pre></td></tr></table></figure><p><code>apply</code> 是將組態設定應用至 GPU 上，<br>如下範例，將啟用 <code>all-1g.10gb</code> 組態(設定檔如上範例所示)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-mig-parted apply -f mig-config.yaml -c all-1g.10gb</span><br></pre></td></tr></table></figure><hr><h2 id="開機執行"><a href="#開機執行" class="headerlink" title="開機執行"></a>開機執行</h2><p>MIG 為一次性的設定，只要系統重啟，皆須重新配置，可透過以下執行檔寫入 linux service，在開機時能根據設定檔自動配置。</p><h2 id="TODO…"><a href="#TODO…" class="headerlink" title="TODO…"></a>TODO…</h2>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> A100 </tag>
            
            <tag> MIG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton 後端執行前處理/後處理</title>
      <link href="2021/03/20/nvidia-triton-inference-server-backend/"/>
      <url>2021/03/20/nvidia-triton-inference-server-backend/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通常在影像相關的模型推論，都會對影像做完前處理後才會丟進模型，以及出來做後處理才會存檔或輸出影像。在前幾篇的範例中，我們將前後處理這兩段放在 Client 端處理，Server 端單純做模型推論，此篇將教學如何將前後處理放在Server 端，並將整個推論流程串起來。</p><p>如還未熟悉 Triton 的可以先看此篇 <a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/">Triton Inference Server 介紹與範例</a>。</p><div class="note info">            <p>其他資料類型的以此類推，本篇將以影像為範例。</p>          </div><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>在 Trtion v2.4.0 版之後，正式提出了 <a href="https://github.com/triton-inference-server/backend/tree/main" target="_blank" rel="noopener">Triton Backend</a> 功能，允許使用者自行拓展或客製化推理引擎，使得整個框架更加的靈活，目前支援的後端引擎如下列所示，其中 <code>TensorRT</code>、<code>ONNX Runtime</code>、<code>TensorFlow</code> 及 <code>PyTorch</code>，請依上線的模型自行調整，這邊就不再贅述；<code>OpenVINO</code> 是可運行 <a href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" target="_blank" rel="noopener">Intel OpenVINO</a> 的模型；<code>DALI</code> 則是透過 GPU 來加速數據讀取及處理的框架，將於日後做更詳盡的介紹 – <a href="https://roychou121.github.io/2021/06/08/nvidia-dali/">NVIDIA DALI 加速資料載入及處理(未完成)</a>。<br>以及 Trtion v2.11.0 釋出最新的 <a href="https://github.com/triton-inference-server/fil_backend" target="_blank" rel="noopener">FIL Backend</a> 可支援多個機器學習框架（包括 XGBoost、LightGBM、Scikit-Learn 和 cuML）所訓練的森林模型部署。<br>本篇將介紹如後透過 Python Backend 來進行影像的前後處理。</p><ul><li>TensorRT</li><li>ONNX Runtime</li><li>TensorFlow</li><li>PyTorch</li><li>OpenVINO</li><li>Python</li><li>DALI</li><li>FIL (Forest Inference LIbrary)</li></ul><hr><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><img src= "/img/loading.gif" data-src="/2021/03/20/nvidia-triton-inference-server-backend/pythonBackend.jpg" class="" title="流程圖"><p>需要編寫類別 <code>TritonPythonModel</code>，來處理推論的請求及響應。<br>其中 <code>TritonPythonModel</code> 包含三個 function：<code>initialize</code>、<code>execute</code>、<code>finalize</code>，基本框架如下。</p><ul><li>initialize : 當模組建立時會被調用，會與設定檔相呼應。</li><li>execute : 當 Client 端發出請求時將被調用，這邊就是放置前處理的地方。</li><li>finalize : 當模組卸載時會被調用，可放置卸載時需要清除的任何事情。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> triton_python_backend_utils <span class="keyword">as</span> pb_utils</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TritonPythonModel</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(self, args)</span>:</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self, requests)</span>:</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> responses</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">finalize</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># TODO</span></span><br></pre></td></tr></table></figure><hr><h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>將用之前<a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/#%E6%92%B0%E5%AF%AB%E7%A8%8B%E5%BC%8F%E7%A2%BC-1">Triton Inference Server 介紹與範例</a>中最後的範例來做示範，mnist 模型訓練及 config 設定照舊，Client 端前處理為下所示，這段將移到 Server 端的 Backend 來處理，這樣Client端的程式只需要傳送及接收影像即可，大幅減輕Client端的負擔。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 前處理</span></span><br><span class="line">img = Image.open(<span class="string">'input.jpg'</span>).convert(<span class="string">'L'</span>)</span><br><span class="line">img = img.resize((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">imgArr = np.asarray(img)/<span class="number">255</span></span><br><span class="line">imgArr = np.expand_dims(imgArr[:, :, np.newaxis], <span class="number">0</span>)</span><br><span class="line">imgArr = imgArr.astype(triton_to_np_dtype(<span class="string">'FP32'</span>))</span><br></pre></td></tr></table></figure><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><h4 id="建立模型庫"><a href="#建立模型庫" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>模型庫中保存著多個模型包。<br>除了 mnist 模型之外，後端的模組也是放在這個目錄下，因為多了前處理後端，Client端就不是直接呼叫mnist模型，而是要建立一個 <code>ensemble</code> 來串起前處理及mnist模型</p><p>以此範例來說<br>模型庫為 <code>model_repository</code><br>模型庫中共存放了 1 個模型包(<code>mnist</code>)、 1 個 python 後端(<code>preprocess_mnist</code>)及 1 個 ensemble (<code>ensemble_mnist</code>)</p><img src= "/img/loading.gif" data-src="/2021/03/20/nvidia-triton-inference-server-backend/repository.PNG" class="" title="建立模型庫"><h4 id="編輯後端檔"><a href="#編輯後端檔" class="headerlink" title="編輯後端檔"></a>編輯後端檔</h4><p>當 python 前處理後端撰寫完之後，要跟模型一樣寫一個 <code>config.pbtxt</code> ，稍後會有範例說明<br>可以看到 <code>initialize</code> 為撈取 <code>config.pbtxt</code> 參數及 <code>output</code> 變數名命<br><code>execute</code> 為前處理程式碼放置的地方<br><code>finalize</code> 本次未使用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> triton_python_backend_utils <span class="keyword">as</span> pb_utils</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TritonPythonModel</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize</span><span class="params">(self, args)</span>:</span></span><br><span class="line">        self.model_config = model_config = json.loads(args[<span class="string">'model_config'</span>])</span><br><span class="line"></span><br><span class="line">        output0_config = pb_utils.get_output_config_by_name(model_config, <span class="string">"OUTPUT0"</span>)</span><br><span class="line">        self.output0_dtype = pb_utils.triton_string_to_numpy(output0_config[<span class="string">'data_type'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">execute</span><span class="params">(self, requests)</span>:</span></span><br><span class="line">        output0_dtype = self.output0_dtype</span><br><span class="line"></span><br><span class="line">        responses = []</span><br><span class="line">        <span class="keyword">for</span> request <span class="keyword">in</span> requests:</span><br><span class="line">            in_0 = pb_utils.get_input_tensor_by_name(request, <span class="string">"INPUT0"</span>)</span><br><span class="line">            </span><br><span class="line">            image = in_0.as_numpy()</span><br><span class="line">            img = Image.open(io.BytesIO(image.tobytes())).convert(<span class="string">'L'</span>)</span><br><span class="line">            img = img.resize((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">            imgArr = np.asarray(img)/<span class="number">255</span></span><br><span class="line">            imgArr = np.expand_dims(imgArr[:, :, np.newaxis], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            out_tensor_0 = pb_utils.Tensor(<span class="string">"OUTPUT0"</span>, imgArr.astype(output0_dtype))</span><br><span class="line"></span><br><span class="line">            inference_response = pb_utils.InferenceResponse(output_tensors=[out_tensor_0])</span><br><span class="line">            responses.append(inference_response)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> responses</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">finalize</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'Cleaning up...'</span>)</span><br></pre></td></tr></table></figure><h4 id="編輯設定檔"><a href="#編輯設定檔" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><p>mnist 模型設定檔沒動，這邊就沒列出</p><p>python 後端設定檔</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"preprocess_mnist"</span></span><br><span class="line">backend: <span class="string">"python"</span></span><br><span class="line">max_batch_size: <span class="number">32</span></span><br><span class="line">input [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"INPUT0"</span></span><br><span class="line">        data_type: TYPE_UINT8</span><br><span class="line">        dims: [ -<span class="number">1</span> ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">output [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"OUTPUT0"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">instance_group [</span><br><span class="line">    &#123;</span><br><span class="line">        kind: KIND_CPU</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>ensemble設定檔</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"ensemble_mnist"</span></span><br><span class="line">platform: <span class="string">"ensemble"</span></span><br><span class="line">max_batch_size: <span class="number">32</span></span><br><span class="line">input [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"INPUT"</span></span><br><span class="line">        data_type: TYPE_UINT8</span><br><span class="line">        dims: [ -<span class="number">1</span> ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">output [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"OUTPUT"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [ <span class="number">10</span> ]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">ensemble_scheduling &#123;</span><br><span class="line">    step [</span><br><span class="line">        &#123;</span><br><span class="line">            model_name: <span class="string">"preprocess_mnist"</span></span><br><span class="line">            model_version: -<span class="number">1</span></span><br><span class="line">            input_map &#123;</span><br><span class="line">                key: <span class="string">"INPUT0"</span></span><br><span class="line">                value: <span class="string">"INPUT"</span></span><br><span class="line">        &#125;</span><br><span class="line">            output_map &#123;</span><br><span class="line">                key: <span class="string">"OUTPUT0"</span></span><br><span class="line">                value: <span class="string">"preprocessed_image"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">        model_name: <span class="string">"mnist"</span></span><br><span class="line">        model_version: -<span class="number">1</span></span><br><span class="line">        input_map &#123;</span><br><span class="line">            key: <span class="string">"flatten_input"</span></span><br><span class="line">            value: <span class="string">"preprocessed_image"</span></span><br><span class="line">        &#125;</span><br><span class="line">        output_map &#123;</span><br><span class="line">            key: <span class="string">"dense_1"</span></span><br><span class="line">            value: <span class="string">"OUTPUT"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="運行伺服器端"><a href="#運行伺服器端" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><p>在執行 <code>tritonserver</code> 之前，如有需要額外安裝套件，可在執行前安裝，如此範例需額外安裝 <code>Pillow</code> 套件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus 1 --name Triton_Server --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v /home/roy/Documents/model_repository/:/models nvcr.io/nvidia/tritonserver:21.09-py3 bash -c "pip install Pillow &amp;&amp;  tritonserver --model-store=/models"</span><br></pre></td></tr></table></figure><p>運行伺服器端後，成功的畫面如下所示。</p><img src= "/img/loading.gif" data-src="/2021/03/20/nvidia-triton-inference-server-backend/runServer.PNG" class="" title="運行伺服器端成功畫面"><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><h4 id="撰寫程式碼"><a href="#撰寫程式碼" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tritonclient.grpc <span class="keyword">as</span> grpcclient</span><br><span class="line"><span class="keyword">from</span> tritonclient.utils <span class="keyword">import</span> triton_to_np_dtype</span><br><span class="line"></span><br><span class="line"><span class="comment">## 前處理</span></span><br><span class="line">img = np.fromfile(<span class="string">'input.jpg'</span>, dtype=<span class="string">'uint8'</span>)</span><br><span class="line">image_data = np.expand_dims(img, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## Client-Server 溝通</span></span><br><span class="line">triton_client = grpcclient.InferenceServerClient(url=<span class="string">'192.168.137.123:8001'</span>, verbose=<span class="number">0</span>)</span><br><span class="line">inputs = []</span><br><span class="line">inputs.append(grpcclient.InferInput(<span class="string">'INPUT'</span>, image_data.shape, <span class="string">'UINT8'</span>))</span><br><span class="line">inputs[<span class="number">0</span>].set_data_from_numpy(image_data)</span><br><span class="line">outputs = []</span><br><span class="line">outputs.append(grpcclient.InferRequestedOutput(<span class="string">'OUTPUT'</span>,class_count=<span class="number">0</span>))</span><br><span class="line">responses = []</span><br><span class="line">responses.append(triton_client.infer(<span class="string">'ensemble_mnist'</span>,inputs,</span><br><span class="line">                    request_id=str(<span class="number">1</span>),</span><br><span class="line">                    model_version=<span class="string">'1'</span>,</span><br><span class="line">                    outputs=outputs))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 後處理</span></span><br><span class="line"><span class="keyword">print</span> (np.argmax(responses[<span class="number">0</span>].as_numpy(<span class="string">'OUTPUT'</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><h4 id="運行客戶端"><a href="#運行客戶端" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>MNIST 測試資料如下圖所示，將圖片放置掛載的目錄下 (如範例 <code>/raid</code>)。</p><img src= "/img/loading.gif" data-src="/2021/03/20/nvidia-triton-inference-server-backend/input.jpg" class="" title="測試資料"><p>將客戶端環境運行起來後，執行撰寫好的程式碼，即可進行推論。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --name Triton_Client -v /raid:/data nvcr.io/nvidia/tritonserver:21.09-py3-sdk bash -c 'python /data/client.py'</span><br></pre></td></tr></table></figure><p>最後 MNIST 推論結果如下圖所示，可以發現有成功的預測出數字。</p><img src= "/img/loading.gif" data-src="/2021/03/20/nvidia-triton-inference-server-backend/result.PNG" class="" title="結果">]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Inference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 20.04 IPMI 設定</title>
      <link href="2021/03/15/ubuntu-ipmitool/"/>
      <url>2021/03/15/ubuntu-ipmitool/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因為常用到，所以特此紀錄方便日後查詢。</p><p>使用 <a href="https://github.com/ipmitool/ipmitool" target="_blank" rel="noopener">ipmitool</a> 設定伺服器網路管理(IPMI)設定檔。</p><hr><h2 id="常用操作指令"><a href="#常用操作指令" class="headerlink" title="常用操作指令"></a>常用操作指令</h2><p>以下範例預設皆為 <code>Channel 1</code>，如為其他 Channel 請自行更改。</p><ul><li><p>顯示 IPMI 網路設置資訊</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool lan print 1</span><br></pre></td></tr></table></figure></li><li><p>設定 IPMI 網路為 DHCP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool lan set 1 ipsrc dhcp</span><br></pre></td></tr></table></figure></li><li><p>設定 IPMI 網路為固定 IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool lan set 1 ipsrc static</span><br><span class="line">sudo ipmitool lan set 1 ipaddr 192.168.0.2</span><br><span class="line">sudo ipmitool lan set 1 netmask 255.255.255.0</span><br><span class="line">sudo ipmitool lan set 1 defgw ipaddr 192.168.0.254</span><br></pre></td></tr></table></figure></li><li><p>顯示全部使用者訊息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool user list 1</span><br></pre></td></tr></table></figure></li><li><p>創建使用者帳號</p><p>以下範例，<code>3</code> 為使用者 ID，<code>roy</code> 為帳號名稱</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool user set name 3 roy</span><br></pre></td></tr></table></figure></li><li><p>設定或修改使用者密碼</p><p>以下範例，<code>3</code> 為使用者 ID，<code>pw123456</code> 為使用者密碼</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool user set password 3 pw123456</span><br></pre></td></tr></table></figure></li><li><p>設定帳號權限</p><p>以下範例，<code>1</code>為 Channel，<code>3</code> 為使用者 ID，<code>privilege</code> 為用戶等級，等級表如下</p><p>1 : callback<br>2 : user<br>3 : operator<br>4 : administrator<br>5 : OEM</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ipmitool channel setaccess 1 3 callin=on ipmi=on link=on privilege=4</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LINUX </tag>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Clara Imaging - AIAA 介紹與範例</title>
      <link href="2021/02/15/nvidia-clara-imaging-aiaa/"/>
      <url>2021/02/15/nvidia-clara-imaging-aiaa/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在監督式模型開發階段中，資料標註是體現資料價值的重要步驟，除了需耗費大量人力及時間之外，標註的好壞也會影響模型訓練的準確性，所以加速標註高質量的數據集，是目前各界重視的議題，近幾年來相關工具也陸陸續續的出現。</p><p>Clara Imaging 是一套能加快醫學影像 (如 CT, MRI, XRAY, PATHOLOGY…) 人工智慧模型開發和部署的應用程式框架，本章將介紹如何使用 Clara Imaging 中的 AIAA 來輔助標註醫學影像，而 Clara 其他功能可參考<a href="https://roychou121.github.io/2021/02/15/nvidia-clara/">CLARA SDK 介紹</a>。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/clara-image.png" class="" title="CLARA IMAGING 流程圖"><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>AIAA 走的是 Client-Server 架構。<br>Server 端主要功能為傳接資料，模型推論及管理。<br>Client 端則為傳接資料，將未標註的影像送至 Server 端，並接收 Server 端回傳的標註結果。目前有兩套現成的醫學影像處理軟體，有 AIAA Client 的插件：MITK 以及 3D Slicer，可直接跟 AIAA Server 溝通。<br>或是透過 AIAA Client API，自行結合如網頁、手機 APP 等來實現與 AIAA Server 的通訊。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/aiaa_struct.png" class="" title="AIAA 架構圖"><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><ul><li>Server Clara AIAA : v3.1.01</li><li>Client 3D Slicer : v4.11.20210226</li><li>Client MITK : v2021.02</li></ul><hr><h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 20.04</li><li>GPU Driver：460.32.03</li><li>Docker：19.03.14</li><li>Docker Image：nvcr.io/nvidia/clara-train-sdk:v3.1.01</li></ul><h3 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝-Docker"><a href="#安裝-Docker" class="headerlink" title="安裝 Docker"></a>安裝 Docker</h4><p>本篇是將系統架設在 Docker 上，可以參考此<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">文章</a> 將 Docker 環境建立起來。</p><h4 id="下載映像檔"><a href="#下載映像檔" class="headerlink" title="下載映像檔"></a>下載映像檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull nvcr.io/nvidia/clara-train-sdk:v3.1.01</span><br></pre></td></tr></table></figure><h3 id="運行步驟"><a href="#運行步驟" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/server.png" class="" title="Server 流程圖"><h4 id="運行伺服器端"><a href="#運行伺服器端" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><p>在運行前需指定此服務要跑幾個 GPU、通訊 Port 以及模型庫的路徑。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus &lt;GPU Number&gt; --name &lt;Conatainer Name&gt; --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p &lt;Host Port&gt;:80 -v &lt;Model Repository Path&gt;:/aiaa nvcr.io/nvidia/clara-train-sdk:v3.1.01 start_aas.sh --workspace /aiaa --monitor true</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">sudo docker run -d --gpus 1 --name roy_clara --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 25000:80 -v /raid/roy/clara:/aiaa nvcr.io/nvidia/clara-train-sdk:v3.1.01 start_aas.sh --workspace /aiaa --monitor true</span><br></pre></td></tr></table></figure><div class="note info">            <p>Port 80 為 HTTP 協定通道</p>          </div><h4 id="配置模型設定檔"><a href="#配置模型設定檔" class="headerlink" title="配置模型設定檔"></a>配置模型設定檔</h4><p>每個模型皆須有設定檔，系統會根據設定檔來運行模型，最基本的設定檔由 5 大元素組成：基本資訊、前處理、推論資訊、後處理、存檔資訊。</p><p><strong>基本資訊</strong> 所需的參數如下</p><ul><li>version : <code>2</code>, <code>3</code></li><li>type : <code>segmentation</code>, <code>annotation</code>, <code>classification</code>, <code>deepgrow</code>, <code>others</code>, <code>pipeline</code></li><li>labels : 根據模型輸出格式來依序填入標籤順序</li><li>description : 描述此模型</li></ul><p>基本資訊範例如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: <span class="string">"3"</span>,</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"annotation"</span>,</span><br><span class="line">  <span class="attr">"labels"</span>: [</span><br><span class="line">    <span class="string">"lung"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"description"</span>: <span class="string">"A pre-trained model for volumetric (3D) annotation of the Lung from CT image"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>前處理</strong> 為影像從檔案讀取到進模型之前，所需處理的步驟，每個模型都不一樣，請依照模型需求依序填入，AIAA 有支援的影像處理模組可查閱 <a href="https://docs.nvidia.com/clara/tlt-mi/nvmidl/api_reference.html" target="_blank" rel="noopener">AIAA API</a>。</p><p>以下為某個模型的前處理範例，處理步驟為讀取醫療影像檔(.nii) -&gt; 調整維度順序 -&gt; 根據分辨率縮放 -&gt; 強度變換，其相對應的模組名稱為 : <code>LoadNifti</code> -&gt; <code>ConvertToChannelsFirst</code> -&gt; <code>ScaleByResolution</code> -&gt; <code>ScaleIntensityRange</code>。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"pre_transforms"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"LoadNifti"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ConvertToChannelsFirst"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ScaleByResolution"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"target_resolution"</span>: [</span><br><span class="line">          <span class="number">1.0</span>,</span><br><span class="line">          <span class="number">1.0</span>,</span><br><span class="line">          <span class="number">1.0</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ScaleIntensityRange"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"a_min"</span>: <span class="number">-21</span>,</span><br><span class="line">        <span class="attr">"a_max"</span>: <span class="number">189</span>,</span><br><span class="line">        <span class="attr">"b_min"</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="attr">"b_max"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"clip"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>推論資訊</strong> 所需的參數如下</p><ul><li>image : <code>image</code>, <code>volume</code></li><li>name : <code>TRTISInference</code>, <code>TFInference</code>，建議使用 <code>TRTISInference</code></li><li>args : 在建立推論時，所需的參數</li><li>node_mapping : 下面 <code>trtis</code> 及 <code>tf</code> 中所對應的輸入輸出名稱</li><li>additional_info : 額外要傳輸給 client 端的訊息</li><li>trtis : Triton 推論所需的參數配置，<code>name</code> 如果選擇 <code>TRTISInference</code>才需要使用，詳細參數可參閱 <a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/">Triton Inference Server 介紹與範例</a></li><li>tf : TF 推論所需的參數配置，<code>name</code> 如果選擇 <code>TFInference</code>才需要使用</li></ul><p>推論資訊範例如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"inference"</span>: &#123;</span><br><span class="line">    <span class="attr">"image"</span>: <span class="string">"image"</span>,</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"TRTISInference"</span>,</span><br><span class="line">    <span class="attr">"args"</span>: &#123;</span><br><span class="line">      <span class="attr">"batch_size"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"roi"</span>: [</span><br><span class="line">        <span class="number">128</span>,</span><br><span class="line">        <span class="number">128</span>,</span><br><span class="line">        <span class="number">128</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"trtis"</span>: &#123;</span><br><span class="line">      <span class="attr">"platform"</span>: <span class="string">"tensorflow_graphdef"</span>,</span><br><span class="line">      <span class="attr">"max_batch_size"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"input"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"name"</span>: <span class="string">"NV_MODEL_INPUT"</span>,</span><br><span class="line">          <span class="attr">"data_type"</span>: <span class="string">"TYPE_FP32"</span>,</span><br><span class="line">          <span class="attr">"dims"</span>: [</span><br><span class="line">            <span class="number">2</span>,</span><br><span class="line">            <span class="number">128</span>,</span><br><span class="line">            <span class="number">128</span>,</span><br><span class="line">            <span class="number">128</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"output"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"name"</span>: <span class="string">"NV_MODEL_OUTPUT"</span>,</span><br><span class="line">          <span class="attr">"data_type"</span>: <span class="string">"TYPE_FP32"</span>,</span><br><span class="line">          <span class="attr">"dims"</span>: [</span><br><span class="line">            <span class="number">2</span>,</span><br><span class="line">            <span class="number">128</span>,</span><br><span class="line">            <span class="number">128</span>,</span><br><span class="line">            <span class="number">128</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"instance_group"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"count"</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="attr">"kind"</span>: <span class="string">"KIND_AUTO"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"tf"</span>: &#123;</span><br><span class="line">      <span class="attr">"input_nodes"</span>: &#123;</span><br><span class="line">        <span class="attr">"image"</span>: <span class="string">"NV_MODEL_INPUT"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"output_nodes"</span>: &#123;</span><br><span class="line">        <span class="attr">"model"</span>: <span class="string">"NV_MODEL_OUTPUT"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>後處理</strong> 為模型推論完成到存檔之前，所需處理的步驟，每個模型都不一樣，請依照模型需求依序填入，AIAA 有支援的影像處理模組可查閱 <a href="https://docs.nvidia.com/clara/tlt-mi/nvmidl/api_reference.html" target="_blank" rel="noopener">AIAA API</a>。</p><p>以下為某個模型的後處理範例，使用 argmax 計算對應的類別 -&gt; 計算極值並加入至新通道 -&gt; 複製 Properties -&gt; 轉換回原始影像大小，其相對應的模組名稱為 : <code>ArgmaxAcrossChannels</code> -&gt; <code>AddExtremePointsChannel</code> -&gt; <code>CopyProperties</code> -&gt; <code>RestoreOriginalShape</code>。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"post_transforms"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ArgmaxAcrossChannels"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"model"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"AddExtremePointsChannel"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"image_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"model"</span>,</span><br><span class="line">        <span class="attr">"points"</span>: <span class="string">"points"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"CopyProperties"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: [</span><br><span class="line">          <span class="string">"model"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"from_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"properties"</span>: [</span><br><span class="line">          <span class="string">"affine"</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"RestoreOriginalShape"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"model"</span>,</span><br><span class="line">        <span class="attr">"src_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"is_label"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>存檔資訊</strong> 為最後推論影像要儲存的格式，AIAA 有支援的儲存模組可查閱 <a href="https://docs.nvidia.com/clara/tlt-mi/nvmidl/api_reference.html" target="_blank" rel="noopener">AIAA API</a>。</p><p>存檔資訊範例如下，將影像存回 NIFTI 格式(.nii)</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"writer"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"WriteNifti"</span>,</span><br><span class="line">    <span class="attr">"file_ext"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="attr">"args"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"prediction"</span>,</span><br><span class="line">      <span class="attr">"dtype"</span>: <span class="string">"uint8"</span>,</span><br><span class="line">      <span class="attr">"revert_canonical"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="上傳模型"><a href="#上傳模型" class="headerlink" title="上傳模型"></a>上傳模型</h4><p>根據不同的模型訓練方式，總共有三種打包模型的方法：MMAR、Triton、Tensorflow(CKPT)。<br>而將模型上傳至 AIAA Server，皆使用 HTTP 請求方法中的 <code>PUT</code> 來上傳。</p><ol><li><p>MMAR</p><p><a href="https://docs.nvidia.com/clara/tlt-mi/nvmidl/mmar.html#medical-model-archive-mmar" target="_blank" rel="noopener">MMAR</a> 為醫療模型檔案目錄的一個標準結構，可用於模型訓練、驗證及推論。<br>將前面步驟撰寫好的模型設定檔及模型，依照 MMAR 架構放置到對應的目錄，並壓縮 MMAR 資料夾成 <code>zip</code> 或 <code>tar</code> 或 <code>gz</code> 或 <code>tgz</code>，即可上傳。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">zip -r &lt;MMAR&gt;.zip &lt;MMAR&gt;</span><br><span class="line">curl -X PUT "&lt;AIAA Server&gt;/admin/model/&lt;Model Name&gt;" -F "data=@&lt;MMAR&gt;.zip"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">zip -r seg_spleen_mmar.zip seg_spleen_mmar</span><br><span class="line">curl -X PUT "192.168.0.100:25000/admin/model/seg_spleen" -F "data=@seg_spleen_mmar.zip"</span><br></pre></td></tr></table></figure></li><li><p>Triton</p><p>如訓練的模型為 <a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/">Triton</a> 所支援的格式，直接將前面步驟撰寫好的模型設定檔及模型檔上傳即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT "&lt;AIAA Server&gt;/admin/model/&lt;Model Name&gt;" -F "config=@&lt;Config&gt;;type=application/json" -F "data=@&lt;Model&gt;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">curl -X PUT "192.168.0.100:25000/admin/model/seg_spleen" -F "config=@config_aiaa.json;type=application/json" -F "data=@model.pt"</span><br></pre></td></tr></table></figure></li><li><p>Tensorflow(CKPT)</p><p>如果訓練的模型格式為 Tensorflow CKPT，則需先將 CKPT 壓縮後，再跟前面步驟撰寫好的模型設定檔一起上傳即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">zip &lt;Model&gt;.zip model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.meta</span><br><span class="line">curl -X PUT "&lt;AIAA Server&gt;/admin/model/&lt;Model Name&gt;" -F "config=@&lt;Config&gt;;type=application/json" -F "data=@&lt;Model&gt;.zip"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">zip model.zip model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.meta</span><br><span class="line">curl -X PUT "192.168.0.100:25000/admin/model/seg_spleen" -F "config=@config_aiaa.json;type=application/json" -F "data=@model.zip"</span><br></pre></td></tr></table></figure><div class="note info">            <p>如果上傳為 CKPT 格式，AIAA Server 接收到後會轉成 TF-TRT 格式。 </p>          </div></li></ol><h4 id="檢查系統狀態"><a href="#檢查系統狀態" class="headerlink" title="檢查系統狀態"></a>檢查系統狀態</h4><p>查看 AIAA Server Logs，預設為最後 100 行，如要看更多行數，需加上 <code>lines</code> 參數</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http://&lt;AIAA Server&gt;/logs</span><br><span class="line">http://&lt;AIAA Server&gt;/logs?lines=200</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">http://192.168.0.100:25000/logs</span><br><span class="line">http://192.168.0.100:25000/logs?lines=200</span><br></pre></td></tr></table></figure><p>列出全部 AIAA Server 上的模型</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http://&lt;AIAA Server&gt;/v1/models</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">http://192.168.0.100:25000/v1/models</span><br></pre></td></tr></table></figure><p>查看 API 的使用情況，預設帳密皆為 <code>admin</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http://&lt;AIAA Server&gt;/v1/dashboard</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">http://192.168.0.100:25000/v1/dashboard</span><br></pre></td></tr></table></figure><hr><h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><h3 id="系統環境-1"><a href="#系統環境-1" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 20.04 Desktop or Windows 10</li><li>Client 3D Slicer : v4.11.20210226</li><li>Client MITK : v2021.02</li></ul><h3 id="安裝步驟-1"><a href="#安裝步驟-1" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝相依套件"><a href="#安裝相依套件" class="headerlink" title="安裝相依套件"></a>安裝相依套件</h4><p>Ubuntu 20.04 Desktop 需安裝相依套件，如果系統為 Windows 10 則不用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 3D Slicer</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install libpulse-dev libnss3 libglu1-mesa libxcb-xinerama0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> MITK</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install build-essential doxygen git graphviz libfreetype6-dev libglu1-mesa-dev libssl-dev libtiff5-dev libwrap0-dev libxcomposite1 libxcursor1 libxi-dev libxkbcommon-x11-0 libxt-dev mesa-common-dev </span><br><span class="line">pip install SimpleITK==1.*</span><br></pre></td></tr></table></figure><h4 id="下載-3D-Slicer-或-MITK"><a href="#下載-3D-Slicer-或-MITK" class="headerlink" title="下載 3D Slicer 或 MITK"></a>下載 3D Slicer 或 MITK</h4><p>兩個都是醫學影像處理軟體，擇一下載即可</p><ul><li><p>Ubuntu 20.04 Desktop 下載方式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 3D Slicer</span></span><br><span class="line">wget https://download.slicer.org/bitstream/1442746 -O Slicer-4.11.20210226-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> MITK</span></span><br><span class="line">wget https://www.mitk.org/download/releases/MITK-2021.02/Nvidia/Ubuntu%2020.04/MITK-v2021.02-linux-x86_64.tar.gz -O MITK-v2021.02-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>Windows 10 下載方式</p><p>3D Slicer 下載<a href="https://download.slicer.org/" target="_blank" rel="noopener">連結</a></p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/3d-slicer-download.PNG" class="" title="3D Slicer 下載"><p>MITK 下載<a href="https://www.mitk.org/wiki/Downloads/NVIDIA_AI-Assisted_Annotation_Client" target="_blank" rel="noopener">連結</a></p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/mitk-download.PNG" class="" title="MITK 下載"></li></ul><h4 id="安裝-3D-Slicer-或-MITK"><a href="#安裝-3D-Slicer-或-MITK" class="headerlink" title="安裝 3D Slicer 或 MITK"></a>安裝 3D Slicer 或 MITK</h4><ul><li><p>Ubuntu 20.04 Desktop 安裝方式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 3D Slicer</span></span><br><span class="line">tar zxvf Slicer-4.11.20210226-linux-amd64.tar.gz</span><br><span class="line">cd Slicer-4.11.20210226-linux-amd64</span><br><span class="line">./Slicer</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> MITK</span></span><br><span class="line">tar zxvf MITK-v2021.02-linux-x86_64.tar.gz</span><br><span class="line">cd MITK-v2021.02-linux-x86_64/</span><br><span class="line">./MitkWorkbench.sh</span><br></pre></td></tr></table></figure></li><li><p>Windows 10 安裝方式</p><p>3D Slicer 執行檔案</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/3d-slicer-install.PNG" class="" title="3D Slicer 安裝"><p>MITK 執行檔案</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/mitk-install.PNG" class="" title="MITK 安裝"></li></ul><h3 id="運行步驟-1"><a href="#運行步驟-1" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/client.png" class="" title="Client 流程圖"><h4 id="串接設備"><a href="#串接設備" class="headerlink" title="串接設備"></a>串接設備</h4><p>目前 AIAA 支援大部分醫療影像格式，在跟 Server 端溝通之前，Client 端需先跟各醫療設備或是 PACS 等進行串接。</p><h4 id="運行客戶端"><a href="#運行客戶端" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>以下分別介紹 3D Slicer 以及 MITK 的運行方式，而自行呼叫 AIAA Client API 的方式將在另一篇文章說明。</p><ul><li><p>3D Slicer</p><p>第一次使用時，需先下載 <code>NvidiaAIAssistedAnnotation</code> 插件，才能使用 AIAA Client 的功能。</p><p>安裝 <code>NvidiaAIAssistedAnnotation</code> 插件步驟如下</p><ol><li><p>點開插件管理介面</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/extension.png" class="" title="選單"></li><li><p>搜尋 <code>NvidiaAIAssistedAnnotation</code>，並點下安裝</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/install3d.PNG" class="" title="安裝插件"></li><li><p>安裝完成後須重啟 3D Slicer</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/restart3d.PNG" class="" title="重啟 3D Slicer"></li><li><p>重啟後點開設定</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/setting3d.PNG" class="" title="設定 3D Slicer"></li><li><p>設定 AIAA Server 資訊，設定完成後就能使用，剩餘步驟可看<a href="https://roychou121.github.io/2021/02/15/nvidia-clara-imaging-aiaa/#%E7%AF%84%E4%BE%8B">實際範例</a>，其他 3D Slicer 的功能可以查看<a href="https://www.slicer.org/wiki/Documentation/4.10/Training" target="_blank" rel="noopener">官方文件</a>。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/aiaa3d.PNG" class="" title="設定 AIAA Server 資訊"></li></ol></li><li><p>MITK</p><p>MITK 有分兩個版本 (原生版及 AIAA 版)，請下載 AIAA 版，並設定好 AIAA Server 資訊後，即可使用，其他 MITK 的功能可以查看<a href="https://www.mitk.org/wiki/Documentation" target="_blank" rel="noopener">官方文件</a>。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/settingmitk.PNG" class="" title="設定 MITK"><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/aiaamitk.PNG" class="" title="設定 AIAA Server 資訊"></li></ul><h4 id="上傳醫療影像"><a href="#上傳醫療影像" class="headerlink" title="上傳醫療影像"></a>上傳醫療影像</h4><p>將於<a href="https://roychou121.github.io/2021/02/15/nvidia-clara-imaging-aiaa/#%E4%B8%8A%E5%82%B3%E9%86%AB%E7%99%82%E5%BD%B1%E5%83%8F-1">實際範例</a>中示範</p><h4 id="查看推論結果"><a href="#查看推論結果" class="headerlink" title="查看推論結果"></a>查看推論結果</h4><p>將於<a href="https://roychou121.github.io/2021/02/15/nvidia-clara-imaging-aiaa/#%E6%9F%A5%E7%9C%8B%E6%8E%A8%E8%AB%96%E7%B5%90%E6%9E%9C-1">實際範例</a>中示範</p><hr><h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>本次範例將示範如何部署輔助標註脾臟的模型，並實際拿醫療影像來測試標註結果。<br>資料集可至 <a href="http://medicaldecathlon.com/" target="_blank" rel="noopener">Medical Segmentation Decathlon</a> 下載。<br>輔助標註脾臟的模型可至 <a href="https://ngc.nvidia.com/catalog/models/nvidia:med:clara_ct_annotation_spleen_amp" target="_blank" rel="noopener">NGC</a> 下載。</p><h3 id="Server-1"><a href="#Server-1" class="headerlink" title="Server"></a>Server</h3><h4 id="運行伺服器端-1"><a href="#運行伺服器端-1" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><p>首先將 AIAA Server 運行起來待命，成功的畫面如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus 1 --name roy_clara --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 25000:80 -v /raid/roy/clara:/aiaa nvcr.io/nvidia/clara-train-sdk:v3.1.01 start_aas.sh --workspace /aiaa --monitor true</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-server.PNG" class="" title="運行 AIAA Server"><h4 id="配置模型設定檔-1"><a href="#配置模型設定檔-1" class="headerlink" title="配置模型設定檔"></a>配置模型設定檔</h4><p>下載範例模型及模型設定檔</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/med/clara_ct_annotation_spleen_amp/versions/1/zip -O clara_ct_annotation_spleen_amp_1.zip</span><br><span class="line">unzip clara_ct_annotation_spleen_amp_1.zip -d clara_ct_annotation_spleen_amp_1</span><br></pre></td></tr></table></figure><p>解壓縮後你會發現這是一個標準的 MMAR 架構，<br>在 <code>models</code> 可以找到模型檔 (<code>model.trt.pb</code>)<br>在 <code>config</code> 可以找到模型設定檔 (<code>config_aiaa.json</code>)</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-model.PNG" class="" title="MMAR 架構"><p>此範例的模型設定檔為 Clara v2 的版本，有興趣的人可以先試試轉成 Clara v3 的格式，日後會釋出給大家參考。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: <span class="string">"2"</span>,</span><br><span class="line">  <span class="attr">"type"</span>: <span class="string">"annotation"</span>,</span><br><span class="line">  <span class="attr">"labels"</span>: [</span><br><span class="line">    <span class="string">"spleen"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"description"</span>: <span class="string">"A pre-trained model for volumetric (3D) annotation of the spleen from CT image"</span>,</span><br><span class="line">  <span class="attr">"pre_transforms"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"LoadNifti"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"AddLabelPoints"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"image_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"label"</span>,</span><br><span class="line">        <span class="attr">"params"</span>: <span class="string">"params"</span>,</span><br><span class="line">        <span class="attr">"points"</span>: <span class="string">"points"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ConvertToChannelsFirst"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: [</span><br><span class="line">          <span class="string">"image"</span>,</span><br><span class="line">          <span class="string">"label"</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"CropImageAndLabel"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"image_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"label"</span>,</span><br><span class="line">        <span class="attr">"pad"</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="attr">"roi"</span>: [</span><br><span class="line">          <span class="number">128</span>,</span><br><span class="line">          <span class="number">128</span>,</span><br><span class="line">          <span class="number">128</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ScaleIntensityRange"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"a_min"</span>: <span class="number">-1024</span>,</span><br><span class="line">        <span class="attr">"a_max"</span>: <span class="number">1024</span>,</span><br><span class="line">        <span class="attr">"b_min"</span>: <span class="number">-1.0</span>,</span><br><span class="line">        <span class="attr">"b_max"</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"clip"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"AddExtremePointsChannel"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"image_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"label"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"inference"</span>: &#123;</span><br><span class="line">    <span class="attr">"image"</span>: <span class="string">"image"</span>,</span><br><span class="line">    <span class="attr">"scanning_window"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"batch_size"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"roi"</span>: [</span><br><span class="line">      <span class="number">128</span>,</span><br><span class="line">      <span class="number">128</span>,</span><br><span class="line">      <span class="number">128</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"padding"</span>: <span class="number">20.0</span>,</span><br><span class="line">    <span class="attr">"tf"</span>: &#123;</span><br><span class="line">      <span class="attr">"input_nodes"</span>: &#123;</span><br><span class="line">        <span class="attr">"image"</span>: <span class="string">"NV_MODEL_INPUT"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"output_nodes"</span>: &#123;</span><br><span class="line">        <span class="attr">"model"</span>: <span class="string">"NV_MODEL_OUTPUT"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"trtis"</span>: &#123;</span><br><span class="line">      <span class="attr">"input_channels"</span>: &#123;</span><br><span class="line">        <span class="attr">"image"</span>: <span class="number">2</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"output_channels"</span>: &#123;</span><br><span class="line">        <span class="attr">"model"</span>: <span class="number">2</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"gpu_instance_count"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"max_batch_size"</span>: <span class="number">8</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"post_transforms"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"FilterProbabilityThreshold"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"model"</span>,</span><br><span class="line">        <span class="attr">"threshold"</span>: <span class="number">0.5</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"SplitAcrossChannels"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"model"</span>,</span><br><span class="line">        <span class="attr">"channel_names"</span>: [</span><br><span class="line">          <span class="string">"background"</span>,</span><br><span class="line">          <span class="string">"prediction"</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"PasteCroppedLabel"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"prediction"</span>,</span><br><span class="line">        <span class="attr">"image_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"label_field"</span>: <span class="string">"label"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"CopyProperties"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: &#123;</span><br><span class="line">        <span class="attr">"fields"</span>: [</span><br><span class="line">          <span class="string">"prediction"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="attr">"from_field"</span>: <span class="string">"image"</span>,</span><br><span class="line">        <span class="attr">"properties"</span>: [</span><br><span class="line">          <span class="string">"affine"</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"writer"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"WriteNifti"</span>,</span><br><span class="line">    <span class="attr">"file_ext"</span>: <span class="string">""</span>,</span><br><span class="line">    <span class="attr">"args"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"prediction"</span>,</span><br><span class="line">      <span class="attr">"dtype"</span>: <span class="string">"uint8"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="上傳模型-1"><a href="#上傳模型-1" class="headerlink" title="上傳模型"></a>上傳模型</h4><p>直接透過剛剛下載的 MMAR 壓縮檔上傳，成功畫面如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT "192.168.0.100:25000/admin/model/annotation_spleen" -F "data=@clara_ct_annotation_spleen_amp_1.zip"</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-upload.PNG" class="" title="上傳成功畫面"><p>也可以走 Triton 的方式，從 MMAR 中取出 <code>config_aiaa.json</code> 及 <code>model.trt.pb</code> 上傳，成功畫面如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X PUT "192.168.0.100:25000/admin/model/annotation_spleen2" -F "config=@config_aiaa.json;type=application/json" -F "data=@model.trt.pb"</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-upload2.PNG" class="" title="上傳成功畫面"><h4 id="檢查系統狀態-1"><a href="#檢查系統狀態-1" class="headerlink" title="檢查系統狀態"></a>檢查系統狀態</h4><p>開啟瀏覽器輸入以下網址</p><ul><li><p>查詢 AIAA Server logs</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.0.100:25000/logs/</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-logs.PNG" class="" title="AIAA Server logs"></li><li><p>查看 AIAA Server 上所有的模型資訊，可以看到剛剛上傳的兩個模型 (<code>annotation_spleen</code>, <code>annotation_spleen2</code>)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.0.100:25000/v1/models</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-models.PNG" class="" title="AIAA Server models"></li><li><p>查看 API 的使用情況，預設帳密皆為 <code>admin</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.0.100:25000/v1/dashboard</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-dashboard-login.PNG" class="" title="AIAA Server dashboard login"><p>進入後可以查看 API 的使用情況</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-dashboard.PNG" class="" title="AIAA Server dashboard"></li></ul><h3 id="Client-1"><a href="#Client-1" class="headerlink" title="Client"></a>Client</h3><h4 id="串接設備-1"><a href="#串接設備-1" class="headerlink" title="串接設備"></a>串接設備</h4><p>由於目前沒有實際的設備可以串接，這邊先以 <a href="https://drive.google.com/file/d/1jzeNU1EKnK81PyTsrx0ujfNl-t0Jo8uE/view?usp=sharing" target="_blank" rel="noopener">MSD Spleen</a> 資料集當作範例</p><h4 id="運行客戶端-1"><a href="#運行客戶端-1" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>本次範例以 3D Slicer 當作 AIAA Client 端，請先確認已安裝好 <code>NvidiaAIAssistedAnnotation</code> 插件<br>開啟 3D Slicer ，並設定好 AIAA Server 的網路位置</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-setting.PNG" class="" title="3D Slicer 設定"><h4 id="上傳醫療影像-1"><a href="#上傳醫療影像-1" class="headerlink" title="上傳醫療影像"></a>上傳醫療影像</h4><p>在 3D Slicer 點選 <code>Load Data</code></p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-loaddata.PNG" class="" title="載入醫療影像"><p>選擇要標註的影像</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-select.PNG" class="" title="檔案選擇"><p>開啟後選擇 <code>Segment Editor</code>，然後新增一個圖層</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno1.PNG" class="" title="選擇 Segment Editor 並新增一個圖層"><p>為此圖層配色集命名，完成後點選 <code>Nvidia AIAA</code></p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno2.PNG" class="" title="為此圖層配色集命名"><p>選擇剛剛上傳的模型，並開始標註</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno3.PNG" class="" title="選擇模型"><p>點選要標註目標物的四周(黃色框框的部分)，點完後按下 <code>Start</code></p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno4.PNG" class="" title="標註目標物的四周"><p>等待推論結果回傳</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno5.PNG" class="" title="等待"><h4 id="查看推論結果-1"><a href="#查看推論結果-1" class="headerlink" title="查看推論結果"></a>查看推論結果</h4><p>查看推論結果</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno6.PNG" class="" title="查看推論結果"><p>如果覺得有誤，可透過左方的工具修正</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno7.PNG" class="" title="修正標註"><p>點選 <code>Show 3D</code> 可查看 3D 畫面</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno8.PNG" class="" title="3D 畫面"><p>確認都沒問題後，就可以存檔</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara-imaging-aiaa/demo-anno9.PNG" class="" title="3D 存檔"><hr><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol><li><a href="https://docs.nvidia.com/clara/tlt-mi/aiaa/index.html" target="_blank" rel="noopener">NVIDIA Imaging - AI-Assisted Annotation</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Healthcare </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> CLARA </tag>
            
            <tag> AIAA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLARA SDK 介紹</title>
      <link href="2021/02/15/nvidia-clara/"/>
      <url>2021/02/15/nvidia-clara/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由於少子化、高齡化、醫護人力不足及照護人力需求大增等問題，智慧醫療的相關課題相繼的被各國所重視，如何有效的導入資通訊技術及系統，來提升醫療效率與醫療服務品質，是目前關鍵的議題。</p><p><a href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" rel="noopener">NVIDIA CLARA</a> 由 NVIDIA 釋出的一套開源軟體 — 醫療照護適用的智慧運算技術解決方案，提供單一平台整合影像、基因體研究、病患監測和藥物開發，讓醫療照護產業能夠創新並加速完成精準醫學的目標，非常適合從事醫學成像或基因組學研究的醫療保健應用程序開發人員。</p><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>根據目前智慧醫療四大議題，Clara 提供相應的解決方案：醫學影像、基因體、智慧醫院及藥物開發，可根據需求挑選來使用。</p><ul><li><a href="https://www.nvidia.com/zh-tw/healthcare/clara-imaging/" target="_blank" rel="noopener">醫學影像</a> (CLARA IMAGING)</li><li><a href="https://www.nvidia.com/zh-tw/healthcare/clara-parabricks/" target="_blank" rel="noopener">基因體</a> (CLARA PARABRICKS)</li><li><a href="https://www.nvidia.com/zh-tw/healthcare/clara-guardian/" target="_blank" rel="noopener">智慧醫院</a> (CLARA GUARDIAN)</li><li><a href="https://www.nvidia.com/zh-tw/healthcare/clara-discovery/" target="_blank" rel="noopener">藥物開發</a> (CLARA DISCOVERY)</li></ul><h3 id="醫學影像-CLARA-IMAGING"><a href="#醫學影像-CLARA-IMAGING" class="headerlink" title="醫學影像 CLARA IMAGING"></a>醫學影像 CLARA IMAGING</h3><p>Clara Imaging 是一套能加快醫學影像(如 CT, MRI, XRAY, PATHOLOGY…)人工智慧模型開發和部署的應用程式框架，根據AI流程可分成三部分，Clara Train、Clara Deploy 及 Clara AGX。<br>Clara Train 包含了醫療影像AI輔助標註及醫療影像模型訓練兩大功能，其中模型訓練這塊，最新加入了AutoML及Federated Learning，讓模型訓練更佳的靈活及有效。<br>Clara Deploy 將 AI 模型與現有醫院基礎設施的接口串接，無痛的建立各個醫學影像推論的資料流。<br>Clara AGX 可與醫療儀器或設備結合，升級為邊緣運算單元，可為醫護人員提供實時的 AI 推論成像。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara/clara-image.png" class="" title="CLARA IMAGING 流程圖"><div class="note info">            <p>Train SDK 4.0 將採用以 Pytorch 為基底的 <a href="https://monai.io/" target="_blank" rel="noopener">MONAI</a> 開源框架，敬請期待。<br>如想搶先體驗，可至<a href="https://developer.nvidia.com/nvidia-clara-train-40-interest-form" target="_blank" rel="noopener">官網</a>的表單填寫申請。</p>          </div><h3 id="基因體-CLARA-PARABRICKS"><a href="#基因體-CLARA-PARABRICKS" class="headerlink" title="基因體 CLARA PARABRICKS"></a>基因體 CLARA PARABRICKS</h3><p>Clara Parabricks 以基因體分析工具組 (GATK) 為基礎，是一款可立即執行的 GPU 加速軟體套件，能為群體基因體研究進行 DNA 生殖細胞變異偵測、為癌症基因體研究進行體細胞 DNA 的變異偵測，以及進行從轉錄體到單細胞分析的 RNA 定序專案。</p><p>如需體驗，可申請一個月的試用，申請<a href="https://www.nvidia.com/en-us/docs/nvidia-parabricks-general/" target="_blank" rel="noopener">連結</a>。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara/clara-parabricks-pipeline.png" class="" title="CLARA PARABRICKS PIPELINE 架構圖"><h3 id="智慧醫院-CLARA-GUARDIAN"><a href="#智慧醫院-CLARA-GUARDIAN" class="headerlink" title="智慧醫院 CLARA GUARDIAN"></a>智慧醫院 CLARA GUARDIAN</h3><p>除了醫學影像或基因研究之外，在醫院中的公共安全或病患照護也是相當重要的議題。<br>Clara Guardian 可用於溫度偵測、防護裝備檢查、病患互動、跌倒防護、急診室安全等多種應用，並可透過 <a href="https://www.nvidia.com/zh-tw/data-center/products/fleet-command/" target="_blank" rel="noopener">NVIDIA Fleet Command</a> 工具來管理整間醫院各個智慧裝置的狀態。</p><p>NVIDIA Fleet Command 目前為試用版，如需體驗可至<a href="https://www.nvidia.com/zh-tw/data-center/products/fleet-command/#subscribe" target="_blank" rel="noopener">官網</a>申請。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara/clara-guardian.png" class="" title="CLARA GUARDIAN 架構圖"><h3 id="藥物開發-CLARA-DISCOVERY"><a href="#藥物開發-CLARA-DISCOVERY" class="headerlink" title="藥物開發 CLARA DISCOVERY"></a>藥物開發 CLARA DISCOVERY</h3><p>Clara Discovery 集合框架、應用程式和人工智慧模型，可進行 GPU 加速的藥物開發，支援基因體、蛋白質組學、顯微技術、虛擬篩選、計算化學、視覺化、臨床影像和自然語言處理 (NLP) 的研究，可在 <a href="https://ngc.nvidia.com/catalog/collections/nvidia:claradiscovery" target="_blank" rel="noopener">NGC</a> 上查看詳細功能。</p><img src= "/img/loading.gif" data-src="/2021/02/15/nvidia-clara/clara-discovery.png" class="" title="CLARA DISCOVERY 架構圖"><hr><h2 id="相關文章"><a href="#相關文章" class="headerlink" title="相關文章"></a>相關文章</h2><p>日後陸陸續續撰寫此套件各個功能的說明與範例，讓各位能快速的上手並應用在實際場域中。</p><ol><li><a href="https://roychou121.github.io/2021/02/15/nvidia-clara-imaging-aiaa/">Clara Imaging - AIAA 介紹與範例</a></li></ol><hr><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol><li><a href="https://developer.nvidia.com/clara" target="_blank" rel="noopener">NVIDIA Clara</a></li><li><a href="https://docs.nvidia.com/clara/" target="_blank" rel="noopener">NVIDIA Clara Documentation</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Healthcare </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> CLARA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 20.04 網路綁定</title>
      <link href="2021/02/04/ubuntu-network-bond/"/>
      <url>2021/02/04/ubuntu-network-bond/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因為常用到，所以特此紀錄方便日後查詢。</p><p>使用 <a href="https://help.ubuntu.com/community/UbuntuBonding" target="_blank" rel="noopener">bonding</a> 模組，將多個網路線綁定。</p><hr><h2 id="綁定模式"><a href="#綁定模式" class="headerlink" title="綁定模式"></a>綁定模式</h2><p>綁定方法總共有 7 種，可根據需求選擇適合的模式。</p><p>詳細說明可參考<a href="https://www.kernel.org/doc/Documentation/networking/bonding.txt" target="_blank" rel="noopener">此文件</a></p><ul><li>mode 0 : balance-rr</li><li>mode 1 : active-backup</li><li>mode 2 : balance-xor</li><li>mode 3 : broadcast</li><li>mode 4 : 802.3ad</li><li>mode 5 : balance-tlb</li><li>mode 6 : balance-alb</li></ul><div class="note info">            <p>如果選擇 mode 4 (802.3ad)，交換器也需要設定為 <code>802.3ad</code> 模式。</p>          </div><h2 id="設定步驟"><a href="#設定步驟" class="headerlink" title="設定步驟"></a>設定步驟</h2><h3 id="確認驅動"><a href="#確認驅動" class="headerlink" title="確認驅動"></a>確認驅動</h3><p>確認是否有 bonding 模組驅動，理論上新版系統的都已內建，較舊的系統則需安裝驅動。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modinfo bonding | more</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/check.PNG" class="" title="確認驅動"><p>如未找到，請安裝套件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install ifenslave</span><br></pre></td></tr></table></figure><h3 id="載入模組"><a href="#載入模組" class="headerlink" title="載入模組"></a>載入模組</h3><p>載入 bonding 模組</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo modprobe bonding</span><br></pre></td></tr></table></figure><h3 id="確認模組已經加載"><a href="#確認模組已經加載" class="headerlink" title="確認模組已經加載"></a>確認模組已經加載</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo lsmod | grep bonding</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/show.PNG" class="" title="確認模組已經加載"><h3 id="開機自動加載"><a href="#開機自動加載" class="headerlink" title="開機自動加載"></a>開機自動加載</h3><p>將 bonding 模組設定開機自動加載</p><p>編輯設定檔</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/modules</span><br></pre></td></tr></table></figure><p>填入 <code>bonding</code> </p><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/config.PNG" class="" title="&#x2F;etc&#x2F;modules 設定檔"><h3 id="查詢網路介面名稱"><a href="#查詢網路介面名稱" class="headerlink" title="查詢網路介面名稱"></a>查詢網路介面名稱</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link</span><br></pre></td></tr></table></figure><p>如下範例，可以看到有兩個網孔，網路介面名稱分別為 <code>enp13s0</code> , <code>enp0s31f6</code> </p><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/IP_link.PNG" class="" title="GPU 網路介面名稱"><h3 id="編輯網路設定檔"><a href="#編輯網路設定檔" class="headerlink" title="編輯網路設定檔"></a>編輯網路設定檔</h3><p>每台系統預設的設定檔檔名未必一樣，可在 <code>/etc/netplan</code> 找到副檔名為 <code>yaml</code> 的設定檔，下圖為例，檔案名稱為 <code>01-netcfg.yaml</code>。</p><p>列出設定檔名稱</p><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/show_yaml.PNG" class="" title="GPU 列出設定檔名稱"><p>編輯設定檔</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/netplan/01-netcfg.yaml</span><br></pre></td></tr></table></figure><h3 id="填入網路綁定資訊"><a href="#填入網路綁定資訊" class="headerlink" title="填入網路綁定資訊"></a>填入網路綁定資訊</h3><p>假設綁定模式為 <code>802.3ad</code>，也稱為 LACP (Link Aggregation Control Protocol)，並選擇將 <code>enp13s0</code> , <code>enp0s31f6</code> 這兩個網路介面綁定。</p><p>固定 IP 設定範例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">renderer:</span> <span class="string">networkd</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">enp13s0:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">enp0s31f6:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">bonds:</span></span><br><span class="line">    <span class="attr">bond4:</span></span><br><span class="line">      <span class="attr">interfaces:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">enp13s0</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">enp0s31f6</span></span><br><span class="line">      <span class="attr">parameters:</span></span><br><span class="line">        <span class="attr">mode:</span> <span class="number">802.</span><span class="string">3ad</span></span><br><span class="line">        <span class="attr">lacp-rate:</span> <span class="string">fast</span></span><br><span class="line">      <span class="attr">addresses:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">"192.168.0.200/24"</span></span><br><span class="line">      <span class="attr">gateway4:</span> <span class="string">"192.168.0.254"</span></span><br><span class="line">      <span class="attr">nameservers:</span></span><br><span class="line">        <span class="attr">addresses:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">"8.8.8.8"</span></span><br><span class="line">          <span class="bullet">-</span> <span class="string">"1.1.1.1"</span></span><br></pre></td></tr></table></figure><p>DHCP IP 設定範例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">renderer:</span> <span class="string">networkd</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">enp13s0:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">enp0s31f6:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">bonds:</span></span><br><span class="line">    <span class="attr">bond4:</span></span><br><span class="line">      <span class="attr">interfaces:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">enp13s0</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">enp0s31f6</span></span><br><span class="line">      <span class="attr">parameters:</span></span><br><span class="line">        <span class="attr">mode:</span> <span class="number">802.</span><span class="string">3ad</span></span><br><span class="line">        <span class="attr">lacp-rate:</span> <span class="string">fast</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="啟用網路設定"><a href="#啟用網路設定" class="headerlink" title="啟用網路設定"></a>啟用網路設定</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan apply</span><br></pre></td></tr></table></figure><p>如果擔心設定有問題或失敗，可以使用 <code>try</code>指令，在執行 <code>120</code> 秒後復原原本設定。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan try</span><br></pre></td></tr></table></figure><h3 id="查詢網路狀態"><a href="#查詢網路狀態" class="headerlink" title="查詢網路狀態"></a>查詢網路狀態</h3><p>查詢綁定後的網路資訊</p><img src= "/img/loading.gif" data-src="/2021/02/04/ubuntu-network-bond/ifconfig.PNG" class="" title="GPU 查詢網路綁定後的狀態">]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NETWORK </tag>
            
            <tag> BOND </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 20.04 網路設定</title>
      <link href="2021/02/03/ubuntu-network/"/>
      <url>2021/02/03/ubuntu-network/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因為常用到，所以特此紀錄方便日後查詢。</p><p>使用 <a href="https://netplan.io/" target="_blank" rel="noopener">netplan</a> 設定 Ubuntu 網路。</p><hr><h2 id="設定步驟"><a href="#設定步驟" class="headerlink" title="設定步驟"></a>設定步驟</h2><h3 id="查詢網路介面名稱"><a href="#查詢網路介面名稱" class="headerlink" title="查詢網路介面名稱"></a>查詢網路介面名稱</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link</span><br></pre></td></tr></table></figure><p>如下範例，可以看到有兩個網孔，網路介面名稱分別為 <code>enp13s0</code> , <code>enp0s31f6</code> </p><img src= "/img/loading.gif" data-src="/2021/02/03/ubuntu-network/IP_link.PNG" class="" title="GPU 網路介面名稱"><h3 id="編輯設定檔"><a href="#編輯設定檔" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h3><p>每台系統預設的設定檔檔名未必一樣，可在 <code>/etc/netplan</code> 找到副檔名為 <code>yaml</code> 的設定檔，下圖為例，檔案名稱為 <code>01-netcfg.yaml</code>。</p><p>列出設定檔名稱</p><img src= "/img/loading.gif" data-src="/2021/02/03/ubuntu-network/show_yaml.PNG" class="" title="GPU 列出設定檔名稱"><p>編輯設定檔</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/netplan/01-netcfg.yaml</span><br></pre></td></tr></table></figure><h3 id="填入網路資訊"><a href="#填入網路資訊" class="headerlink" title="填入網路資訊"></a>填入網路資訊</h3><p>固定 IP 設定範例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">renderer:</span> <span class="string">networkd</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">enp13s0:</span></span><br><span class="line">      <span class="attr">addresses:</span> <span class="string">[</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.200</span><span class="string">/24</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">gateway4:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.254</span></span><br><span class="line">      <span class="attr">nameservers:</span></span><br><span class="line">          <span class="attr">addresses:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">"8.8.8.8"</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">"1.1.1.1"</span></span><br></pre></td></tr></table></figure><p>DHCP IP 設定範例</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">version:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">renderer:</span> <span class="string">networkd</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">enp0s31f6:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="啟用網路設定"><a href="#啟用網路設定" class="headerlink" title="啟用網路設定"></a>啟用網路設定</h3><p>啟用網路設定</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan apply</span><br></pre></td></tr></table></figure><p>如果擔心設定有問題或失敗，可以使用 <code>try</code>指令，在執行 <code>120</code> 秒後復原原本設定。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan try</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NETWORK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 20.04 NVME SSD 開機失敗</title>
      <link href="2021/01/25/ubuntu-install-nvme/"/>
      <url>2021/01/25/ubuntu-install-nvme/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>部分型號的 NVME SSD，如果將系統裝在此硬碟上，會遇到開機失敗的情況。<br>解決方法就是在開機時，重新引導至 NVME 的磁區。</p><hr><h2 id="解決方法"><a href="#解決方法" class="headerlink" title="解決方法"></a>解決方法</h2><p>開機後進入 GRUB 選單，按 <code>e</code> 編輯，在 <code>linux</code> 那行的尾端填入以下指令，最後用 <code>Crtl+x</code> 或 <code>F10</code> 開機。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvme_core.default_ps_max_latency_us=5500 acpi=off</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2021/01/25/ubuntu-install-nvme/grub.png" class="" title="GRUB 選單範例"><p>成功開機後，編輯 <code>/etc/default/grub</code>，將此設定寫入開機指令，即可解決此問題。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/default/grub</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT="nvme_core.default_ps_max_latency_us=5500"</span><br><span class="line">GRUB_CMDLINE_LINUX="acpi=off"</span><br></pre></td></tr></table></figure><p>重啟設定，完成！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-grub</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> OS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LINUX </tag>
            
            <tag> OS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 延長終端機連線自動退出時間</title>
      <link href="2020/11/23/ubuntu-ssh-timeout/"/>
      <url>2020/11/23/ubuntu-ssh-timeout/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 ssh 終端機介面，如一段時間未操作，則連線會自動退出，如不想中斷或想延長中斷時間，可在環境變數中設定。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timed out waiting for input: auto-logou</span><br></pre></td></tr></table></figure><hr><h2 id="設置"><a href="#設置" class="headerlink" title="設置"></a>設置</h2><p>編輯環境變數</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 方法一</span></span><br><span class="line">sudo vim ~/.bashrc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 方法二</span></span><br><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure><p>加入自動退出的時間，<code>0</code> 為永不退出，大於 <code>0</code> 則是幾秒後退出。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 永不退出</span></span><br><span class="line">export TMOUT=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 300 秒後退出</span></span><br><span class="line">export TMOUT=300</span><br></pre></td></tr></table></figure><p>重新啟用環境變數</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UBUNTU </tag>
            
            <tag> SSH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NVIDIA GPU 開啟持久化模式</title>
      <link href="2020/11/14/nvidia-gpu-persistenced/"/>
      <url>2020/11/14/nvidia-gpu-persistenced/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>每當一個或多個客戶端打開設備文件時，GPU狀態就會保持加載在驅動程序中。一旦所有客戶端都關閉了設備文件，除非啟用了持久化模式，否則GPU狀態將被卸載。</p><p>為避免每次初始化所造成的延遲而影響到效能，可開啟GPU持久化模式。</p><hr><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><p>指定 GPU 開啟持久化模式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi -i &lt;GPU ID&gt; -pm 1</span><br></pre></td></tr></table></figure><p>指定 GPU 關閉持久化模式</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi -i &lt;GPU ID&gt; -pm 0</span><br></pre></td></tr></table></figure><div class="note info">            <p>如未指定 GPU，則代表全部 GPU 都開啟或關閉</p>          </div><img src= "/img/loading.gif" data-src="/2020/11/14/nvidia-gpu-persistenced/pm.png" class="" title="開啟持久化範例"><hr><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>方法一在機器重新啟動後，設定將會清空，如要保留則需寫入 <code>service</code> 中</p><p>編輯 <code>/lib/systemd/system/nvidia-persistenced.service</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /lib/systemd/system/nvidia-persistenced.service</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=NVIDIA Persistence Daemon</span><br><span class="line">After=syslog.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=/var/run/nvidia-persistenced/nvidia-persistenced.pid</span><br><span class="line">Restart=always</span><br><span class="line">ExecStart=/usr/bin/nvidia-persistenced --verbose</span><br><span class="line">ExecStopPost=/bin/rm -rf /var/run/nvidia-persistenced/*</span><br><span class="line">TimeoutSec=300</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p>啟用服務</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable nvidia-persistenced</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Install </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> GPU </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Instance GPU (MIG) 設定</title>
      <link href="2020/10/29/nvidia-A100-MIG/"/>
      <url>2020/10/29/nvidia-A100-MIG/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Multi-Instance GPU（MIG）功能使 NVIDIA A100 GPU 可以安全地切割為多達七個用於 CUDA 應用的獨立 GPU 實例，從而為多個用戶提供獨立的 GPU 資源，以優化 GPU 的利用率。此功能對於 GPU 工作負載利用率低的特別有用，因此使用 MIG 技術，可在單張 GPU 上並行運行不同的工作負載以最大化利用率。</p><div class="note info">            <p>目前只有 NVIDIA Tesla A100 及 A30 擁有這個功能。</p>          </div><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/mig.png" class="" title="Multi-Instance GPU（MIG）示意圖"><hr><h2 id="名詞解釋"><a href="#名詞解釋" class="headerlink" title="名詞解釋"></a>名詞解釋</h2><ul><li>GPU Engine : GPU Engine 是 GPU 上的工作引擎，如 copy engine (CE)、DMAs、NVDEC、NVENC 等等。</li><li>GPU Memory Slice : GPU Memory Slice 是 GPU 內存的最小單位，一張 GPU 的內存總共由 8 個 GPU Memory Slice 所組成。</li><li>GPU SM Slice : GPU SM Slice 是 GPU SM 的最小單位，一張 GPU 的 SM 總共由 7 個 GPU SM Slice 所組成。</li><li>GPU Slice : GPU Slice 是 GPU 的最小單位，它是由一個 GPU Memory Slice 和一個 GPU SM Slice 所組成。</li><li>GPU Instance (GI) : GPU Instance 是 GPU slices 和 GPU engine 的組合，GPU Instance 中會共享所有 GPU slices 和 GPU engine。其中每個 GPU Instance 可再進一步細分為 Compute Instance。</li><li>Compute Instance (CI) : Compute Instance 是其父類別 GPU Instance 的子集。</li></ul><hr><h2 id="注意事項"><a href="#注意事項" class="headerlink" title="注意事項"></a>注意事項</h2><ul><li>MIG 模式只能在 CUDA 11 / R450 的 Linux 系統使用，目前驅動版本為 <code>450.80.02</code>。</li><li>在設定 MIG 時，使用者須擁有超級用戶的權限。</li><li>一旦 GPU 為 MIG 模式，即可動態的設置 GPU，無須重啟。</li><li>當 GPU 為 MIG 模式，不支援 graphics APIs，如 OpenGL, Vulkan 等等。</li><li>當 GPU 為 MIG 模式，不支援 GPU to GPU P2P。</li><li>當 GPU 為 MIG 模式，CUDA 應用程式會將 GPU Instance 中的 Compute Instance 視為單個 CUDA 設備。</li></ul><hr><h2 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h2><p>GPU 驅動安裝可參考此<a href="https://roychou121.github.io/2020/07/12/ubuntu-install-gpu-driver/">文章</a>，請下載 <code>450.80.02</code> 或更新的版本。</p><hr><h2 id="MIG-設定"><a href="#MIG-設定" class="headerlink" title="MIG 設定"></a>MIG 設定</h2><h3 id="建立流程"><a href="#建立流程" class="headerlink" title="建立流程"></a>建立流程</h3><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/createp.PNG" class="" title="建立 MIG 流程"><h4 id="啟用-MIG-模式"><a href="#啟用-MIG-模式" class="headerlink" title="啟用 MIG 模式"></a>啟用 MIG 模式</h4><p>通常預設 MIG 模式是未啟用的狀態，首先要先指定 GPU 來啟用 MIG。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi -i 0 -mig 1</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/mig1.PNG" class="" title="啟用 MIG 模式"><h4 id="查看-GI-可用組合"><a href="#查看-GI-可用組合" class="headerlink" title="查看 GI 可用組合"></a>查看 GI 可用組合</h4><p>總共有五種模式可以選擇，其中 <code>Instances</code> 可查詢剩餘可切割的數量。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -lgip</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/lgip.PNG" class="" title="查看 GI 可用組合"><p>以 NVIDIA A100 40G 為例，最大利用率的排列組合如下圖，可根據需求做選擇。</p><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/migall.PNG" class="" title="全部 GI 的排列組合"><div class="note warning">            <p>在建立 GI 的順序很重要，建議由大建到小(如上圖須由左到右)，以免發生記憶體破碎的問題。</p>          </div><!-- GI 其位置及對應的 ID 表如下<img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/placement.PNG" class="" title="GI 其位置及對應的 ID 表"> --><h4 id="建立-GI"><a href="#建立-GI" class="headerlink" title="建立 GI"></a>建立 GI</h4><p>假設我要建立兩個 <code>3g.20gb</code> 的 GI，建立指令可以用 <code>Name</code> 或 <code>ID</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ID</span></span><br><span class="line">sudo nvidia-smi mig -i 0 -cgi 9</span><br><span class="line"><span class="meta">#</span><span class="bash"> Name</span></span><br><span class="line">sudo nvidia-smi mig -i 0 -cgi 3g.20gb</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/cgi.PNG" class="" title="建立 GI"><p>查詢已經建立的 GI</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -lgi</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/lgi.PNG" class="" title="查詢 GI"><h4 id="查看-CI-可用組合"><a href="#查看-CI-可用組合" class="headerlink" title="查看 CI 可用組合"></a>查看 CI 可用組合</h4><p>指定 GI (GI Instance ID)，來查詢其 CI 可用的組合，<code>*</code>為預設 CI。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -gi 1 -lcip</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/lcip.PNG" class="" title="查看 CI 可用組合"><h4 id="建立-CI"><a href="#建立-CI" class="headerlink" title="建立 CI"></a>建立 CI</h4><p>假設我要建立兩個 <code>1c.3g.20gb</code> 的 GI，建立指令可以用 <code>Name</code> 或 <code>ID</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ID</span></span><br><span class="line">sudo nvidia-smi mig -i 0 -gi 0 -cci 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Name</span></span><br><span class="line">sudo nvidia-smi mig -i 0 -gi 1 -cci 1c.3g.20gb</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/cci.PNG" class="" title="建立 CI"><p>查詢已經建立的 CI (指定 GI)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -gi 1 -lci</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/lci.PNG" class="" title="查詢 CI"><div class="note info">            <p>如果在建 GI 時，想要用預設的 CI，在建GI時加入 <code>-C</code> 參數即可。<br>GPU Driver &gt; <code>450.80.02</code> 才有此功能。</p><p>範例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -cgi 9 -C</span><br></pre></td></tr></table></figure>          </div><h3 id="移除流程"><a href="#移除流程" class="headerlink" title="移除流程"></a>移除流程</h3><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/destroyp.PNG" class="" title="移除 MIG 流程"><h4 id="移除-CI"><a href="#移除-CI" class="headerlink" title="移除 CI"></a>移除 CI</h4><p>指定 GI 及 CI 來移除 CI。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -gi 1 -ci 0,1 -dci</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/dci.PNG" class="" title="移除 CI"><h4 id="移除-GI"><a href="#移除-GI" class="headerlink" title="移除 GI"></a>移除 GI</h4><p>指定 GI 來移除 GI。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi mig -i 0 -gi 1 -dgi</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/dgi.PNG" class="" title="移除 GI"><h4 id="關閉-MIG-模式"><a href="#關閉-MIG-模式" class="headerlink" title="關閉 MIG 模式"></a>關閉 MIG 模式</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvidia-smi -i 0 -mig 0</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/mig0.PNG" class="" title="關閉 MIG 模式"><hr><h2 id="使用-MIG"><a href="#使用-MIG" class="headerlink" title="使用 MIG"></a>使用 MIG</h2><p>假設目前 GPU MIG 切法如下，一個 <code>2g.10gb</code>、三個 <code>1c.3g.20gb</code></p><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/ex.PNG" class="" title="MIG 範例"><p>可以用 <code>GPU ID + MIG DEV ID</code> 或 <code>UUID</code> 來指派 MIG GPU</p><h3 id="用-ID-來指派-GPU"><a href="#用-ID-來指派-GPU" class="headerlink" title="用 ID 來指派 GPU"></a>用 ID 來指派 GPU</h3><p>ID 查詢如下圖，假設我要指派 <code>GPU 0</code> 上的 <code>MIG DEV 1</code> 和 <code>MIG DEV 3</code></p><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/migid.PNG" class="" title="MIG ID"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --gpus '"device=0:1,0:3"' nvcr.io/nvidia/tensorflow:20.11-tf2-py3 bash</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/runmig.PNG" class="" title="透過 docker 來跑 CUDA 應用程式"><p>查詢可用的 MIG GPU</p><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/exmignvidiasmi.PNG" class="" title="查詢可用的 MIG GPU"><h3 id="用-UUID-來指派-GPU"><a href="#用-UUID-來指派-GPU" class="headerlink" title="用 UUID 來指派 GPU"></a>用 UUID 來指派 GPU</h3><p>UUID 查詢如下圖，假設我要指派 <code>MIG-GPU-bc104fe1-14dd-ddc0-dae2-f13f99547443/2/2</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi -L</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/uuid.PNG" class="" title="MIG UUID"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --gpus '"device=MIG-GPU-bc104fe1-14dd-ddc0-dae2-f13f99547443/2/2"' nvcr.io/nvidia/tensorflow:20.11-tf2-py3 bash</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/runmiguuid.PNG" class="" title="透過 docker 來跑 CUDA 應用程式"><p>查詢可用的 MIG GPU</p><img src= "/img/loading.gif" data-src="/2020/10/29/nvidia-A100-MIG/exmignvidiasmiuuid.PNG" class="" title="查詢可用的 MIG GPU"><h2 id="其他文章"><a href="#其他文章" class="headerlink" title="其他文章"></a>其他文章</h2><ul><li><a href="http://localhost:4000/2021/05/22/nvidia-mig-parted/" target="_blank" rel="noopener">透過 MIG-PARTED 管理 MIG</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> A100 </tag>
            
            <tag> A30 </tag>
            
            <tag> MIG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 20.04 建置 Kubernetes (支援 GPU)</title>
      <link href="2020/10/02/nvidia-deepops/"/>
      <url>2020/10/02/nvidia-deepops/</url>
      
        <content type="html"><![CDATA[<div class="note info">            <p>2021/03/12 軟體版本更新至 v21.03</p>          </div><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Kubernetes（K8s）是一個開源系統，用於自動化容器應用程序的部署，擴展和管理。<br>然而安裝 K8s 系統相當繁瑣，對於新手來說會遇到各式各樣的問題，更別說要建構一整座叢集了。好消息是，目前越來越多簡化 K8s 安裝步驟的工具，本章就要來介紹由 NVIDIA 維運的建置工具 <a href="https://github.com/NVIDIA/deepops" target="_blank" rel="noopener">DeepOps</a>。</p><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>DeepOps 項目主要用於快速佈署 Kubernetes 及 Slurm 在 GPU 服務器叢集和共享單個強大節點（例如 <a href="https://www.nvidia.com/zh-tw/data-center/dgx-systems/" target="_blank" rel="noopener">NVIDIA DGX Systems</a>）的最佳實踐。DeepOps 具高彈性，可以進行調整或以模塊化方式使用，以匹配特定使用情境的集群需求。</p><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul><li>利用 Ansible 提供點到點來設置整個群集管理堆棧</li><li>提供腳本可用於快速部署 Kubeflow 和連接 NFS 存儲</li><li>可安裝 Slurm，Kubernetes 或兩者的混合 (Slurm 安裝將於日後另行介紹)</li><li>提供 K8s 儀錶板及資源監控介面</li></ul><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><ul><li>21.03</li></ul><table><thead><tr><th align="center">Component</th><th align="center">v21.03</th></tr></thead><tbody><tr><td align="center">Kubespray</td><td align="center"><a href="https://github.com/kubernetes-incubator/kubespray/tree/b39a196cfbfc63c368fd064b00137bc666340958" target="_blank" rel="noopener">b39a196</a></td></tr><tr><td align="center"><a href="https://github.com/kubernetes/kubernetes" target="_blank" rel="noopener">Kubernetes</a></td><td align="center">1.18.9</td></tr><tr><td align="center"><a href="https://github.com/coreos/etcd" target="_blank" rel="noopener">Etcd</a></td><td align="center">3.4.3</td></tr><tr><td align="center"><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a></td><td align="center">19.03.14</td></tr><tr><td align="center"><a href="https://github.com/projectcalico/calico" target="_blank" rel="noopener">Calico</a></td><td align="center">3.15.2</td></tr><tr><td align="center"><a href="https://helm.sh/" target="_blank" rel="noopener">Helm</a></td><td align="center">3.4.1</td></tr><tr><td align="center"><a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/" target="_blank" rel="noopener">Dashboard</a></td><td align="center">2.0.3</td></tr><tr><td align="center"><a href="https://ngc.nvidia.com/catalog/containers/nvidia:k8s:dcgm-exporter" target="_blank" rel="noopener">DCGM Exporter</a></td><td align="center">2.0.13-2.1.2</td></tr><tr><td align="center"><a href="https://prometheus-community.github.io/helm-charts" target="_blank" rel="noopener">Monitoring</a></td><td align="center">10.0.2</td></tr></tbody></table><hr><h2 id="建置範例"><a href="#建置範例" class="headerlink" title="建置範例"></a>建置範例</h2><h3 id="架構"><a href="#架構" class="headerlink" title="架構"></a>架構</h3><table><thead><tr><th align="center">Hostname</th><th align="center">IP Address</th><th align="center">IP Interface</th><th align="center">SSH Port</th><th align="center">OS</th><th align="center">GPU</th><th align="center">Role</th></tr></thead><tbody><tr><td align="center">k8sm01</td><td align="center">192.168.149.128</td><td align="center">ens33</td><td align="center">22</td><td align="center">Ubuntu 20.04.2</td><td align="center">NO</td><td align="center">Master Node</td></tr><tr><td align="center">k8sm02</td><td align="center">192.168.149.129</td><td align="center">ens33</td><td align="center">22</td><td align="center">Ubuntu 20.04.2</td><td align="center">NO</td><td align="center">Master Node</td></tr><tr><td align="center">k8sm03</td><td align="center">192.168.149.130</td><td align="center">ens33</td><td align="center">22</td><td align="center">Ubuntu 20.04.2</td><td align="center">NO</td><td align="center">Master Node</td></tr><tr><td align="center">k8sc01</td><td align="center">192.168.149.134</td><td align="center">ens33</td><td align="center">22</td><td align="center">Ubuntu 20.04.2</td><td align="center">YES</td><td align="center">Compute Node</td></tr><tr><td align="center">k8sc02</td><td align="center">192.168.149.135</td><td align="center">ens33</td><td align="center">22</td><td align="center">Ubuntu 20.04.2</td><td align="center">YES</td><td align="center">Compute Node</td></tr></tbody></table><h3 id="事前準備"><a href="#事前準備" class="headerlink" title="事前準備"></a>事前準備</h3><p>請在 Master Node 擇一節點操作</p><p>下載 DeepOps 軟體包</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone --recurse-submodules https://github.com/NVIDIA/deepops.git -b release-21.03</span><br><span class="line">cd deepops</span><br></pre></td></tr></table></figure><p>安裝套件及產生 <code>config</code> 資料夾</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo -H ./scripts/setup.sh</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/setup.PNG" class="" title="安裝套件"><p>編輯建置設定檔 (ini)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim config/inventory</span><br></pre></td></tr></table></figure><p>將資料輸入之後存檔離開</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[all]</span><br><span class="line">k8sm01 ansible_host&#x3D;192.168.149.128 ansible_port&#x3D;22 ansible_interfaces&#x3D;ens33</span><br><span class="line">k8sm02 ansible_host&#x3D;192.168.149.129 ansible_port&#x3D;22 ansible_interfaces&#x3D;ens33</span><br><span class="line">k8sm03 ansible_host&#x3D;192.168.149.130 ansible_port&#x3D;22 ansible_interfaces&#x3D;ens33</span><br><span class="line">k8sc01 ansible_host&#x3D;192.168.149.134 ansible_port&#x3D;22 ansible_interfaces&#x3D;ens33</span><br><span class="line">k8sc02 ansible_host&#x3D;192.168.149.135 ansible_port&#x3D;22 ansible_interfaces&#x3D;ens33</span><br><span class="line"></span><br><span class="line">######</span><br><span class="line"># KUBERNETES</span><br><span class="line">######</span><br><span class="line">[kube-master]</span><br><span class="line">k8sm01</span><br><span class="line">k8sm02</span><br><span class="line">k8sm03</span><br><span class="line"></span><br><span class="line">[etcd]</span><br><span class="line">k8sm01</span><br><span class="line">k8sm02</span><br><span class="line">k8sm03</span><br><span class="line"></span><br><span class="line">[kube-node]</span><br><span class="line">k8sc01</span><br><span class="line">k8sc02</span><br><span class="line"></span><br><span class="line">[k8s-cluster:children]</span><br><span class="line">kube-master</span><br><span class="line">kube-node</span><br></pre></td></tr></table></figure><h3 id="建置-Master-節點"><a href="#建置-Master-節點" class="headerlink" title="建置 Master 節點"></a>建置 Master 節點</h3><p>佈署管理節點 (Master Nodes)，第一次使用需輸入 ssh(-k) 及 sudo(-K) 密碼</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -l kube-master -k -K playbooks/k8s-cluster.yml</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/master.PNG" class="" title="佈署管理節點"><p>運行完成成功畫面，要確認 <code>failed</code> 為 <code>0</code></p><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/master_output.PNG" class="" title="運行完成成功畫面"><p>確認管理節點皆成功建置完成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/master_nodes.PNG" class="" title="確認管理節點皆成功建置完成"><h3 id="建置-Compute-節點"><a href="#建置-Compute-節點" class="headerlink" title="建置 Compute 節點"></a>建置 Compute 節點</h3><p>佈署計算節點 (Compute Nodes)，第一次使用需輸入 ssh(-k) 及 sudo(-K) 密碼</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -l k8s-cluster -k -K playbooks/k8s-cluster.yml</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/compute.PNG" class="" title="佈署計算節點"><p>運行完成成功畫面，要確認 <code>failed</code> 為 <code>0</code></p><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/compute_output.PNG" class="" title="運行完成成功畫面"><p>設定 Compute 節點的 <code>kubernetes.io/role</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl label --overwrite nodes k8sc01 kubernetes.io/role=compute</span><br><span class="line">kubectl label --overwrite nodes k8sc02 kubernetes.io/role=compute</span><br></pre></td></tr></table></figure><p>確認計算節點皆成功建置完成</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/10/02/nvidia-deepops/compute_nodes.PNG" class="" title="確認管理節點皆成功建置完成"><hr><h2 id="K8s-維護"><a href="#K8s-維護" class="headerlink" title="K8s 維護"></a>K8s 維護</h2><h3 id="安裝-Kubernetes-Dashboard"><a href="#安裝-Kubernetes-Dashboard" class="headerlink" title="安裝 Kubernetes Dashboard"></a>安裝 Kubernetes Dashboard</h3><p>創建管理用戶並安裝儀錶板和 token，如日後忘記 token ，同指令可再執行一次即可獲得。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bash ./scripts/k8s/deploy_dashboard_user.sh</span><br></pre></td></tr></table></figure><ul><li>Dashboard: https://&lt; Master Node IP &gt;:31443</li></ul><h3 id="安裝-Monitoring"><a href="#安裝-Monitoring" class="headerlink" title="安裝 Monitoring"></a>安裝 Monitoring</h3><p>佈署 DCGM、Prometheus 和 Grafana 來監控各節點的資源使用情況</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bash ./scripts/k8s/deploy_monitoring.sh</span><br></pre></td></tr></table></figure><ul><li>Grafana: http://&lt; Master Node IP &gt;:30200</li><li>Prometheus: http://&lt; Master Node IP &gt;:30500</li><li>Alertmanager: http://&lt; Master Node IP &gt;:30400</li></ul><h3 id="增加節點"><a href="#增加節點" class="headerlink" title="增加節點"></a>增加節點</h3><p>回到建置設定檔 <code>config/inventory</code>，將新的節點加入後執行以下指令，即可增加節點</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook -l k8s-cluster -k -K submodules/kubespray/scale.yml</span><br></pre></td></tr></table></figure><h3 id="移除節點"><a href="#移除節點" class="headerlink" title="移除節點"></a>移除節點</h3><p>將要移除的節點名稱填入，如下範例 (移除 k8sc01 及 k8sc02 兩個節點)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ansible-playbook submodules/kubespray/remove-node.yml --extra-vars "node=k8sc01,k8sc02"</span><br></pre></td></tr></table></figure><h3 id="升級叢集"><a href="#升級叢集" class="headerlink" title="升級叢集"></a>升級叢集</h3><div class="note info">            <p>TODO</p>          </div><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol><li><a href="https://github.com/NVIDIA/deepops" target="_blank" rel="noopener">DeepOps Github</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> KUBERNETES </tag>
            
            <tag> DEEPOPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 Proxy 設定</title>
      <link href="2020/10/02/ubuntu-proxy/"/>
      <url>2020/10/02/ubuntu-proxy/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>因為常用到，所以特此紀錄方便日後查詢。</p><hr><h2 id="APT-Proxy-設定"><a href="#APT-Proxy-設定" class="headerlink" title="APT Proxy 設定"></a>APT Proxy 設定</h2><h3 id="建立設定檔"><a href="#建立設定檔" class="headerlink" title="建立設定檔"></a>建立設定檔</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apt/apt.conf.d/proxy.conf</span><br></pre></td></tr></table></figure><h3 id="填入-Porxy-資訊"><a href="#填入-Porxy-資訊" class="headerlink" title="填入 Porxy 資訊"></a>填入 Porxy 資訊</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Acquire::http::Proxy "http://user:password@proxy.server:port/";</span><br><span class="line">Acquire::https::Proxy "https://user:password@proxy.server:port/";</span><br></pre></td></tr></table></figure><h3 id="測試是否成功"><a href="#測試是否成功" class="headerlink" title="測試是否成功"></a>測試是否成功</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><hr><h2 id="其他軟體-Proxy-設定"><a href="#其他軟體-Proxy-設定" class="headerlink" title="其他軟體 Proxy 設定"></a>其他軟體 Proxy 設定</h2><p>如 <code>git</code>、<code>docker</code>、<code>pip</code>等要走 proxy 了話，就要將 porxy 設定寫入環境變數中，方能生效。</p><h3 id="編輯環境變數檔"><a href="#編輯環境變數檔" class="headerlink" title="編輯環境變數檔"></a>編輯環境變數檔</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="填入-Porxy-資訊-1"><a href="#填入-Porxy-資訊-1" class="headerlink" title="填入 Porxy 資訊"></a>填入 Porxy 資訊</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">http_proxy="http://user:password@proxy.server:port/"</span><br><span class="line">https_proxy="https://user:password@proxy.server:port/"</span><br><span class="line">ftp_proxy="ftp://user:password@proxy.server:port/"</span><br><span class="line">no_proxy="localhost,127.0.0.1"</span><br><span class="line"></span><br><span class="line">HTTP_PROXY="http://user:password@proxy.server:port/"</span><br><span class="line">HTTPS_PROXY="https://user:password@proxy.server:port/"</span><br><span class="line">FTP_PROXY="ftp://user:password@proxy.server:port/"</span><br><span class="line">NO_PROXY="localhost,127.0.0.1"</span><br></pre></td></tr></table></figure><h3 id="重啟環境變數"><a href="#重啟環境變數" class="headerlink" title="重啟環境變數"></a>重啟環境變數</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PROXY </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton Inference Server 介紹與範例</title>
      <link href="2020/07/20/nvidia-triton-inference-server/"/>
      <url>2020/07/20/nvidia-triton-inference-server/</url>
      
        <content type="html"><![CDATA[<div class="note info">            <p>2021/03/02 軟體版本更新至 v2.7.0</p>          </div><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>隨著深度學習技術快速的成長，在應用環境中部署和運行 AI 模型的需求也與日俱增。然而開發一個推論解決方案來部署這些模型是一項艱鉅的任務，延遲、吞吐量、支援多個 AI 框架、並行多個模型、GPU 最佳化 … 等因素，皆是要考慮到的重點，因此如何進行快速部署及管理成為一件複雜卻必須做的事情。</p><p><a href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" rel="noopener">NVIDIA Triton Inference Server</a> 由 NVIDIA 釋出的一套開源軟體 — 模型推論解決方案，具低延遲、高吞吐等特性，可透過 HTTP 或 GRPC 端點提供客戶端推理服務及服務管理，大幅簡化 AI 模型部署的流程。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/triton.png" class="" title="Triton Inference Server 架構"><div class="note info">            <p>由於 Triton 系統龐大再加上篇幅限制，本章注重在基本功能的操作，較深的功能將於日後配合專案來介紹。</p>          </div><hr><h2 id="介紹"><a href="#介紹" class="headerlink" title="介紹"></a>介紹</h2><p>Triton 走的是 Client-Server 架構。<br>Server 端主要功能為傳接資料，模型推論及管理。<br>Client 端則為傳接資料，透過 Triton Client API，自行結合如網頁、手機 APP 等來實現與 Triton Server 的通訊。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/sc.png" class="" title="Server、Client 示意圖"><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul><li>支援多種 AI 框架<ul><li>TensorRT (plan)</li><li>ONNX (onnx)</li><li>TorchScript (pt)</li><li>Tensorflow (graphdef, savedmodel)</li><li>OpenVINO (xml+bin)</li></ul></li><li>支援客製化模組<ul><li>Python (py)</li><li>DALI (dali)</li></ul></li><li>可同時運行多個模型</li><li>可將多個模型串接成一個大模型 (Ensemble Model)</li><li>支援 HTTP 和 GRPC 的接口</li><li>支援將模型庫放在 Google Cloud Storage 、 Amazon S3 或 Azure Storage 中</li><li>具自我監控功能，可顯示 GPU 的利用率，服務器的吞吐量，以及服務器延遲等指標</li><li>適用於部署框架 (Kubernetes) </li><li>允許使用自定義後端 (C++ 或 Python)</li></ul><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><ul><li>2.7.0</li></ul><hr><h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 20.04</li><li>GPU Driver：460.27.04</li><li>Docker：19.03.14</li><li>Docker Image：nvcr.io/nvidia/tritonserver:21.02-py3</li></ul><h3 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝-Docker"><a href="#安裝-Docker" class="headerlink" title="安裝 Docker"></a>安裝 Docker</h4><p>本篇是將系統架設在 Docker 上，可以參考此<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">文章</a> 將 Docker 環境建立起來。</p><h4 id="下載映像檔"><a href="#下載映像檔" class="headerlink" title="下載映像檔"></a>下載映像檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull nvcr.io/nvidia/tritonserver:21.02-py3</span><br></pre></td></tr></table></figure><h3 id="運行步驟"><a href="#運行步驟" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/server.png" class="" title="Server 流程圖"><h4 id="模型轉換"><a href="#模型轉換" class="headerlink" title="模型轉換"></a>模型轉換</h4><p>系統支援的模型如下，如訓練時所使用的框架非下述所示，則需進行轉換。</p><ul><li>Tensorflow (graphdef, savedmodel)</li><li>TensorRT (plan)</li><li>ONNX (onnx)</li><li>PyTorch (pt)</li><li>OpenVINO (xml+bin)</li></ul><div class="note info">            <p>為了增加系統效能，建議模型都要過 TensorRT 編譯。</p>          </div><h4 id="建立模型庫"><a href="#建立模型庫" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>模型庫中保存著多個模型包。<br>每個模型包皆由版本及設定檔所組成，版本建議以自然數依序命名 (Ex. 1,2,3…)。</p><p>建立模型庫範例如下圖所示：<br>以此範例來說<br>模型庫為 <code>model-repository</code><br>模型庫中共存放了4個模型包 (<code>mnistTensorrt</code>, <code>mnist-tftrt</code>, <code>tensorflowGraphdef</code>, <code>tensorflowSavedmodel</code>)<br>其中以 <code>mnist-tftrt</code> 模型包為例，<code>mnist-tftrt</code> 為此模型的命名，資料夾中存放了版本 <code>1</code> 的模型及設定檔。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/repository.png" class="" title="建立模型庫"><h4 id="編輯設定檔"><a href="#編輯設定檔" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><p>每個模型包皆須有設定檔，系統會根據設定檔來運行模型，最基本的設定檔由 5 大元素組成：模型名稱、模型框架、最大批次大小、輸入及輸出層的資訊、GPU 實例資訊。</p><p>更詳盡的參數說明可以參考<a href="https://github.com/triton-inference-server/server/blob/master/docs/model_configuration.md" target="_blank" rel="noopener">官方文件</a>。</p><p>編輯設定檔範例如下圖所示：</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/config.png" class="" title="編輯設定檔"><div class="note info">            <p>設定檔中的模型名稱需與資料夾的模型名稱一致。</p>          </div><div class="note info">            <p>最大批次大小為推論批次設定的最大值，不一定是實際推論批次大小。</p>          </div><h4 id="運行伺服器端"><a href="#運行伺服器端" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><p>在運行前需指定此服務要跑幾個 GPU、走哪些 Port 以及模型庫的路徑。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus &lt;GPU Number&gt; --name &lt;Conatainer Name&gt; --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p &lt;Host Port&gt;:8000 -p &lt;Host Port&gt;:8001 -p &lt;Host Port&gt;:8002 -v &lt;Model Repository Path&gt;:/models nvcr.io/nvidia/tritonserver:21.02-py3 tritonserver --model-store=/models</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">sudo docker run -d --gpus all --name Triton_Server --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v /home/user/Documents/model-repository:/models nvcr.io/nvidia/tritonserver:21.02-py3 tritonserver --model-store=/models</span><br></pre></td></tr></table></figure><div class="note info">            <p>Port 8000 為 HTTP 協定通道<br>Port 8001 為 GRPC 協定通道</p>          </div><h4 id="檢查系統狀態"><a href="#檢查系統狀態" class="headerlink" title="檢查系統狀態"></a>檢查系統狀態</h4><p>檢查系統是否正常的運行中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v localhost:8000/v2/health/ready</span><br></pre></td></tr></table></figure><p>檢查模型的狀態：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET v2/models[/$&#123;MODEL_NAME&#125;[/versions/$&#123;MODEL_VERSION&#125;]]/stats</span><br></pre></td></tr></table></figure><p>Triton 提供 Prometheus Metrics，內容主要為 GPU 狀態和請求統計資訊等：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8002/metrics</span><br></pre></td></tr></table></figure><hr><h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><h3 id="系統環境-1"><a href="#系統環境-1" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 20.04</li><li>Docker：19.03.14</li><li>Docker Image：nvcr.io/nvidia/tritonserver:21.02-py3-sdk</li></ul><h3 id="安裝步驟-1"><a href="#安裝步驟-1" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝-Docker-1"><a href="#安裝-Docker-1" class="headerlink" title="安裝 Docker"></a>安裝 Docker</h4><p>本篇是將系統架設在 Docker 上，可以參考此<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">文章</a> 將 Docker 環境建立起來。</p><h4 id="下載映像檔-1"><a href="#下載映像檔-1" class="headerlink" title="下載映像檔"></a>下載映像檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull nvcr.io/nvidia/tritonserver:21.02-py3-sdk</span><br></pre></td></tr></table></figure><h3 id="運行步驟-1"><a href="#運行步驟-1" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/client.png" class="" title="Client 流程圖"><h4 id="串接設備"><a href="#串接設備" class="headerlink" title="串接設備"></a>串接設備</h4><p>目前主流要推論的資料為數據、影像、聲音以及文字，在跟 Server 端溝通之前，Client 端需先跟各設備進行串接。</p><p>如影像型推論，就需跟攝影機、機台、儲存設備、呈現平台…等串接。</p><h4 id="撰寫程式碼"><a href="#撰寫程式碼" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><p>Client 端程式碼撰寫主要分成三大部分，依序為</p><ul><li>前處理<br>此部分主要處裡的事項為資訊進模型前的所有處理，如影像解碼、維度轉換、訊號處理等等。</li><li>Client-Server 溝通<br>指定將推論的模型資訊，透過 HTTP 或 GRPC 跟 Server 溝通。<br>官方範例可以參考<a href="https://github.com/triton-inference-server/server/tree/master/src/clients/python/examples" target="_blank" rel="noopener">官方範例</a>。</li><li>後處理<br>此部分主要處裡的事項為接到 Server 回傳來推論結果後的所有處理，如儲存檔案、訊息整理、結果呈現等等。</li></ul><div class="note info">            <p>前後處理會因不同的應用實例有所差異，此部分不是本章的重點。<br>本章將會著重在說明 Triton Client-Server 基本的溝通函數，其他更深入的函數將在日後介紹。</p>          </div><h4 id="運行客戶端"><a href="#運行客戶端" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>在運行前需確認 Server 的 IP、走的協定 (HTTP or GRPC) 以及讀取儲存資料的位置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --name &lt;Container Name&gt; -v &lt;Data Path&gt;:/data nvcr.io/nvidia/tritonserver:21.02-py3-sdk bash -c '&lt;Client Code&gt;'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">sudo docker run -d --name Triton_Client -v /home/user/Documents/data:/data nvcr.io/nvidia/tritonserver:21.02-py3-sdk bash -c 'python /data/client.py'</span><br></pre></td></tr></table></figure><hr><h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>接下來將以大家耳熟能詳的 <a href="https://www.tensorflow.org/quantum/tutorials/mnist" target="_blank" rel="noopener">MNIST</a> 所訓練出的模型當作範例，由於訓練模型不是本篇的重點，可以直接下載訓練好的模型進行後續的練習。</p><h3 id="Server-1"><a href="#Server-1" class="headerlink" title="Server"></a>Server</h3><h4 id="訓練模型"><a href="#訓練模型" class="headerlink" title="訓練模型"></a>訓練模型</h4><p>此部分以 MNIST 資料集和簡單的 CNN 模型當作範例。<br>撰寫框架為 TensorFlow v2，來源為<a href="https://www.tensorflow.org/datasets/keras_example" target="_blank" rel="noopener">官方範本</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.compat.v2 <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line">tf.enable_v2_behavior()</span><br><span class="line"></span><br><span class="line">(ds_train, ds_test), ds_info = tfds.load(</span><br><span class="line">    <span class="string">'mnist'</span>,</span><br><span class="line">    split=[<span class="string">'train'</span>, <span class="string">'test'</span>],</span><br><span class="line">    shuffle_files=<span class="literal">True</span>,</span><br><span class="line">    as_supervised=<span class="literal">True</span>,</span><br><span class="line">    with_info=<span class="literal">True</span>,</span><br><span class="line">    try_gcs=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_img</span><span class="params">(image, label)</span>:</span></span><br><span class="line">  <span class="string">"""Normalizes images: `uint8` -&gt; `float32`."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.cast(image, tf.float32) / <span class="number">255.</span>, label</span><br><span class="line"></span><br><span class="line">ds_train = ds_train.map(</span><br><span class="line">    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)</span><br><span class="line">ds_train = ds_train.cache()</span><br><span class="line">ds_train = ds_train.shuffle(ds_info.splits[<span class="string">'train'</span>].num_examples)</span><br><span class="line">ds_train = ds_train.batch(<span class="number">128</span>)</span><br><span class="line">ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ds_test = ds_test.map(</span><br><span class="line">    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)</span><br><span class="line">ds_test = ds_test.batch(<span class="number">128</span>)</span><br><span class="line">ds_test = ds_test.cache()</span><br><span class="line">ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(</span><br><span class="line">    optimizer=tf.keras.optimizers.Adam(<span class="number">0.001</span>),</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.fit(</span><br><span class="line">    ds_train,</span><br><span class="line">    epochs=<span class="number">6</span>,</span><br><span class="line">    validation_data=ds_test,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 模型儲存</span></span><br><span class="line">model.save(<span class="string">'model.savedmodel'</span>)</span><br></pre></td></tr></table></figure><h4 id="建立模型庫-1"><a href="#建立模型庫-1" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>以上面的模型為例，建立出的模型庫如下圖所示。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/repository_ex.PNG" class="" title="建立模型庫"><h4 id="編輯設定檔-1"><a href="#編輯設定檔-1" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><p>以下的參數為必要欄位，其他深入或客製化的參數，可以參考<a href="https://github.com/triton-inference-server/server/blob/master/docs/model_configuration.md" target="_blank" rel="noopener">官網文件</a>。</p><div class="note info">            <p>使用 <code>gpu_execution_accelerator</code> 可在運行 Triton 時，轉成 TensorRT 來加速。<br>只支援 TensorFlow、ONNX。</p>          </div><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"mnist"</span></span><br><span class="line">platform: <span class="string">"tensorflow_savedmodel"</span></span><br><span class="line">max_batch_size: <span class="number">32</span></span><br><span class="line">input [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"flatten_input"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        format: FORMAT_NHWC</span><br><span class="line">        dims: [<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">output [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"dense_1"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [<span class="number">10</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">instance_group [</span><br><span class="line">    &#123;</span><br><span class="line">        kind: KIND_GPU</span><br><span class="line">        count: <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">optimization &#123; execution_accelerators &#123;</span><br><span class="line">    gpu_execution_accelerator : [ &#123;</span><br><span class="line">        name : <span class="string">"tensorrt"</span></span><br><span class="line">        parameters &#123; key: <span class="string">"precision_mode"</span> value: <span class="string">"FP16"</span> &#125;&#125;]</span><br><span class="line">&#125;&#125;</span><br><span class="line"></span><br><span class="line">version_policy &#123; latest &#123; num_versions: <span class="number">1</span> &#125; &#125;</span><br><span class="line"></span><br><span class="line">dynamic_batching &#123;</span><br><span class="line">  preferred_batch_size: [ <span class="number">4</span>, <span class="number">8</span> ]</span><br><span class="line">  max_queue_delay_microseconds: <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="運行伺服器端-1"><a href="#運行伺服器端-1" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus all --name Triton_Server --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v /home/user/Documents/model-repository:/models nvcr.io/nvidia/tritonserver:21.02-py3 tritonserver --model-store=/models --backend-config=tensorflow,version=2 --backend-config=tensorflow,allow-soft-placement=0</span><br></pre></td></tr></table></figure><p>運行伺服器端後，成功的畫面如下所示。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/runServer.PNG" class="" title="運行伺服器端成功畫面"><h4 id="檢查系統狀態-1"><a href="#檢查系統狀態-1" class="headerlink" title="檢查系統狀態"></a>檢查系統狀態</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v localhost:8000/v2/health/ready</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/healthReady.PNG" class="" title="health ready 畫面"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl localhost:8000/v2/models/mnist/versions/1/stats</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/stats.PNG" class="" title="模型狀態"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost:8002/metrics</span><br></pre></td></tr></table></figure><p>部分 Metrics 畫面：</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/metrics.PNG" class="" title="部分 metrics 畫面"><h3 id="Cleint"><a href="#Cleint" class="headerlink" title="Cleint"></a>Cleint</h3><h4 id="串接設備-1"><a href="#串接設備-1" class="headerlink" title="串接設備"></a>串接設備</h4><p>由於目前沒有實際的設備可以串接，此部分直接取用 MNIST 測試資料集中一張影像當作範例，最後將接到的推論結果直接顯示在螢幕上。</p><p>MNIST 測試資料如下圖所示，將圖片放置掛載的目錄下 (如範例 <code>/home/user/data</code>)。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/input.jpg" class="" title="測試資料"><h4 id="撰寫程式碼-1"><a href="#撰寫程式碼-1" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tritonclient.grpc <span class="keyword">as</span> grpcclient</span><br><span class="line"><span class="keyword">from</span> tritonclient.utils <span class="keyword">import</span> triton_to_np_dtype</span><br><span class="line"></span><br><span class="line"><span class="comment">## 前處理</span></span><br><span class="line">img = Image.open(<span class="string">'input.jpg'</span>).convert(<span class="string">'L'</span>)</span><br><span class="line">img = img.resize((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">imgArr = np.asarray(img)/<span class="number">255</span></span><br><span class="line">imgArr = np.expand_dims(imgArr[:, :, np.newaxis], <span class="number">0</span>)</span><br><span class="line">imgArr = imgArr.astype(triton_to_np_dtype(<span class="string">'FP32'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Client-Server 溝通</span></span><br><span class="line">triton_client = grpcclient.InferenceServerClient(url=<span class="string">'localhost:8001'</span>, verbose=<span class="number">0</span>)</span><br><span class="line">inputs = []</span><br><span class="line">inputs.append(grpcclient.InferInput(<span class="string">'flatten_input'</span>, imgArr.shape, <span class="string">'FP32'</span>))</span><br><span class="line">inputs[<span class="number">0</span>].set_data_from_numpy(imgArr)</span><br><span class="line">outputs = []</span><br><span class="line">outputs.append(grpcclient.InferRequestedOutput(<span class="string">'dense_1'</span>,class_count=<span class="number">0</span>))</span><br><span class="line">responses = []</span><br><span class="line">responses.append(triton_client.infer(<span class="string">'mnist'</span>,inputs,</span><br><span class="line">                    request_id=str(<span class="number">1</span>),</span><br><span class="line">                    model_version=<span class="string">'1'</span>,</span><br><span class="line">                    outputs=outputs))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 後處理</span></span><br><span class="line"><span class="keyword">print</span> (np.argmax(responses[<span class="number">0</span>].as_numpy(<span class="string">'dense_1'</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><h4 id="運行客戶端-1"><a href="#運行客戶端-1" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>將客戶端環境運行起來後，執行撰寫好的程式碼，即可進行推論。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --name Triton_Client -v /home/user/data:/data nvcr.io/nvidia/tritonserver:21.02-py3-sdk bash -c 'python /data/client.py'</span><br></pre></td></tr></table></figure><p>最後 MNIST 推論結果如下圖所示，可以發現有成功的預測出數字。</p><img src= "/img/loading.gif" data-src="/2020/07/20/nvidia-triton-inference-server/result.PNG" class="" title="結果"><hr><h2 id="其他文章"><a href="#其他文章" class="headerlink" title="其他文章"></a>其他文章</h2><p>日後陸陸續續撰寫此套件各個功能的說明與範例，讓各位能快速的上手並應用在實際場域中。</p><ul><li><a href="https://roychou121.github.io/2021/03/20/nvidia-triton-inference-server-backend/">Triton 後端執行前處理/後處理</a></li><li><a href="https://roychou121.github.io/2021/05/22/nvidia-triton-label/">Triton 分類推論輸出轉成可讀性類別名稱</a></li><li><a href="https://roychou121.github.io/2021/05/22/nvidia-triton-model-analyzer/">Triton 模型壓力測試</a> (未完成…)</li></ul><hr><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol><li><a href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" rel="noopener">Triton Inference Server</a></li><li><a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html" target="_blank" rel="noopener">Triton Inference Server Documentation</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Inference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 安裝 Anaconda3</title>
      <link href="2020/07/20/ubuntu-install-anaconda/"/>
      <url>2020/07/20/ubuntu-install-anaconda/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如何在 Ubuntu 18.04 上安裝 Anaconda3 ?</p><hr><h2 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>Python：3.7.6</li><li>Anaconda3：2020.02</li></ul><h3 id="步驟"><a href="#步驟" class="headerlink" title="步驟"></a>步驟</h3><h4 id="安裝使用工具-選"><a href="#安裝使用工具-選" class="headerlink" title="安裝使用工具 (選)"></a>安裝使用工具 (選)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install vim wget</span><br></pre></td></tr></table></figure><h4 id="下載-Anaconda3"><a href="#下載-Anaconda3" class="headerlink" title="下載 Anaconda3"></a>下載 <code>Anaconda3</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><h4 id="執行安裝檔"><a href="#執行安裝檔" class="headerlink" title="執行安裝檔"></a>執行安裝檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-2020.02-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><h4 id="閱讀-License"><a href="#閱讀-License" class="headerlink" title="閱讀 License"></a>閱讀 License</h4><p>一開始會跑出 license，按 <code>Enter</code> 看完</p><img src= "/img/loading.gif" data-src="/2020/07/20/ubuntu-install-anaconda/license.PNG" class="" title="閱讀 license"><h4 id="同意-License"><a href="#同意-License" class="headerlink" title="同意 License"></a>同意 License</h4><p>輸入 <code>yes</code> 同意並繼續</p><img src= "/img/loading.gif" data-src="/2020/07/20/ubuntu-install-anaconda/accept.PNG" class="" title="同意 license"><h4 id="儲存路徑"><a href="#儲存路徑" class="headerlink" title="儲存路徑"></a>儲存路徑</h4><p>如果不改變位置，輸入 <code>Enter</code> 繼續執行</p><img src= "/img/loading.gif" data-src="/2020/07/20/ubuntu-install-anaconda/path.PNG" class="" title="儲存路徑"><h4 id="加入環境變數"><a href="#加入環境變數" class="headerlink" title="加入環境變數"></a>加入環境變數</h4><p>輸入 <code>yes</code> ，把 anaconda 加入環境變數</p><img src= "/img/loading.gif" data-src="/2020/07/20/ubuntu-install-anaconda/bashrc.PNG" class="" title="加入環境變數"><h4 id="修改權限"><a href="#修改權限" class="headerlink" title="修改權限"></a>修改權限</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -R $USER:$USER ~/anaconda3</span><br></pre></td></tr></table></figure><h4 id="重啟環境變數"><a href="#重啟環境變數" class="headerlink" title="重啟環境變數"></a>重啟環境變數</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h4 id="檢查-Anaconda-是否安裝成功"><a href="#檢查-Anaconda-是否安裝成功" class="headerlink" title="檢查 Anaconda 是否安裝成功"></a>檢查 Anaconda 是否安裝成功</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/20/ubuntu-install-anaconda/python.PNG" class="" title="檢查 Anaconda 是否安裝成功">]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 設定 DNS</title>
      <link href="2020/07/15/ubuntu-dns/"/>
      <url>2020/07/15/ubuntu-dns/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 Ubuntu 16.04 以上的作業系統，有時候會發生 DNS 跑掉的情況，而從<code>/etc/resolv.conf</code>更改後，雖可以正常使用，但重開機後又回跳回原本的設定，原因是因為此檔案會被 <code>systemd-resolvd</code>自動修改，所以本篇將介紹兩種正確的設定 DNS 的方式。</p><hr><h2 id="方法一：修改-systemd-resolv"><a href="#方法一：修改-systemd-resolv" class="headerlink" title="方法一：修改 systemd-resolv"></a>方法一：修改 <code>systemd-resolv</code></h2><h3 id="編輯-resolved-conf"><a href="#編輯-resolved-conf" class="headerlink" title="編輯 resolved.conf"></a>編輯 <code>resolved.conf</code></h3><p>編輯 <code>/etc/systemd/resolved.conf</code>，在 <code>DNS=</code>欄位中輸入慣用的 dns server</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/systemd/resolved.conf</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Resolve]</span><br><span class="line">DNS&#x3D;8.8.8.8 8.8.4.4</span><br><span class="line">#FallbackDNS&#x3D;</span><br><span class="line">#Domains&#x3D;</span><br><span class="line">LLMNR&#x3D;no</span><br><span class="line">#MulticastDNS&#x3D;no</span><br><span class="line">#DNSSEC&#x3D;no</span><br><span class="line">#Cache&#x3D;yes</span><br><span class="line">#DNSStubListener&#x3D;yes</span><br></pre></td></tr></table></figure><h3 id="重啟服務"><a href="#重啟服務" class="headerlink" title="重啟服務"></a>重啟服務</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart systemd-networkd</span><br><span class="line">sudo systemctl restart systemd-resolved</span><br></pre></td></tr></table></figure><hr><h2 id="方法二：使用-resolvconf-軟體"><a href="#方法二：使用-resolvconf-軟體" class="headerlink" title="方法二：使用 resolvconf 軟體"></a>方法二：使用 <code>resolvconf</code> 軟體</h2><h3 id="下載套件"><a href="#下載套件" class="headerlink" title="下載套件"></a>下載套件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install resolvconf</span><br></pre></td></tr></table></figure><h3 id="編輯-head"><a href="#編輯-head" class="headerlink" title="編輯 head"></a>編輯 <code>head</code></h3><p>編輯 <code>/etc/resolvconf/resolv.conf.d/head</code>，輸入慣用的 dns server</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/resolvconf/resolv.conf.d/head</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver 8.8.4.4</span><br></pre></td></tr></table></figure><h3 id="重啟服務-1"><a href="#重啟服務-1" class="headerlink" title="重啟服務"></a>重啟服務</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service resolvconf restart</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>針對已啟用 Docker Container 修改 Port</title>
      <link href="2020/07/15/docker-container-change-port/"/>
      <url>2020/07/15/docker-container-change-port/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>假如某一天，你突然想改變 port 的對應或者是新增或移除 port ，該怎麼做呢？</p><div class="note warning">            <p>理論上 Container 為一次性的概念，所以當要改設定時，建議建立新的 Container 較為恰當。</p>          </div><hr><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="方法一：重建-Container"><a href="#方法一：重建-Container" class="headerlink" title="方法一：重建 Container"></a>方法一：重建 Container</h3><p>如前言所說，這是推薦方法。</p><h4 id="停止要修改的-Container"><a href="#停止要修改的-Container" class="headerlink" title="停止要修改的 Container"></a>停止要修改的 Container</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker stop &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><h4 id="把-Container-建成-Image"><a href="#把-Container-建成-Image" class="headerlink" title="把 Container 建成 Image"></a>把 Container 建成 Image</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker commit &lt;Container ID or Name&gt; &lt;Image ID&gt;</span><br></pre></td></tr></table></figure><h4 id="把剛剛創的-Image-重新建立新的-Container-並指定所需的-Port"><a href="#把剛剛創的-Image-重新建立新的-Container-並指定所需的-Port" class="headerlink" title="把剛剛創的 Image 重新建立新的 Container 並指定所需的 Port"></a>把剛剛創的 Image 重新建立新的 Container 並指定所需的 Port</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --name &lt;Container Name&gt; -p &lt;Host&gt;:&lt;Container&gt; &lt;Image ID&gt; bash</span><br></pre></td></tr></table></figure><h3 id="方法二：修改-Container"><a href="#方法二：修改-Container" class="headerlink" title="方法二：修改 Container"></a>方法二：修改 Container</h3><h4 id="停止要修改的-Container-1"><a href="#停止要修改的-Container-1" class="headerlink" title="停止要修改的 Container"></a>停止要修改的 Container</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker stop &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><h4 id="進入-root-帳號"><a href="#進入-root-帳號" class="headerlink" title="進入 root 帳號"></a>進入 root 帳號</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo su -</span><br></pre></td></tr></table></figure><h4 id="修改-Container-的設定檔-hostconfig-json"><a href="#修改-Container-的設定檔-hostconfig-json" class="headerlink" title="修改 Container 的設定檔 hostconfig.json"></a>修改 Container 的設定檔 <code>hostconfig.json</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /var/lib/docker/containers/&lt;Container ID&gt;/hostconfig.json</span><br></pre></td></tr></table></figure><p>假設原本的 port 對應為 9453 → 22</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"PortBindings"</span>: &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                <span class="attr">"HostIp"</span>: <span class="string">""</span>,</span><br><span class="line">                <span class="attr">"HostPort"</span>: <span class="string">"9453"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改成 8888 → 22 ，其他以此類推</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"PortBindings"</span>: &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                <span class="attr">"HostIp"</span>: <span class="string">""</span>,</span><br><span class="line">                <span class="attr">"HostPort"</span>: <span class="string">"8888"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="修改-Container-的設定檔-config-v2-json"><a href="#修改-Container-的設定檔-config-v2-json" class="headerlink" title="修改 Container 的設定檔 config.v2.json"></a>修改 Container 的設定檔 <code>config.v2.json</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /var/lib/docker/containers/&lt;Container ID&gt;/config.v2.json</span><br></pre></td></tr></table></figure><p>假設原本的 port 對應為 9453 → 22</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"ExposedPorts"</span> : &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>:&#123;&#125;,<span class="attr">"9453/tcp"</span>:&#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"Ports"</span> : &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>:[&#123;<span class="attr">"HostIp"</span>:<span class="string">"0.0.0.0"</span>,<span class="attr">"HostPort"</span>:<span class="string">"9453"</span>&#125;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改成 8888 → 22 ，其他以此類推</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"ExposedPorts"</span> : &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>:&#123;&#125;,<span class="attr">"8888/tcp"</span>:&#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"Ports"</span> : &#123;</span><br><span class="line">        <span class="attr">"22/tcp"</span>:[&#123;<span class="attr">"HostIp"</span>:<span class="string">"0.0.0.0"</span>,<span class="attr">"HostPort"</span>:<span class="string">"8888"</span>&#125;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="重啟-Docker-Engine"><a href="#重啟-Docker-Engine" class="headerlink" title="重啟 Docker Engine"></a>重啟 Docker Engine</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker restart</span><br></pre></td></tr></table></figure><h4 id="離開-root-帳號及重新啟動-Container"><a href="#離開-root-帳號及重新啟動-Container" class="headerlink" title="離開 root 帳號及重新啟動 Container"></a>離開 root 帳號及重新啟動 Container</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br><span class="line">sudo docker start &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DOCKER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jupyter Notebook 增加密碼保護</title>
      <link href="2020/07/15/jupyter-password/"/>
      <url>2020/07/15/jupyter-password/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>如果你不要每次執行 <code>jupyter lab</code> 時都要打 <code>token</code> ，那就自己設個密碼吧。</p><hr><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="產生設定檔"><a href="#產生設定檔" class="headerlink" title="產生設定檔"></a>產生設定檔</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure><h3 id="設定密碼"><a href="#設定密碼" class="headerlink" title="設定密碼"></a>設定密碼</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-notebook password</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JUPYTER </tag>
            
            <tag> PYTHON </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>查詢日本景點的 Mapcode</title>
      <link href="2020/07/15/mapcode/"/>
      <url>2020/07/15/mapcode/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>每年都會到日本玩的人越來越多，自駕的也不在少數。但如果有自駕過的人就會知道，因為語言不同，在輸入導航時常常要查很久，甚至有時候連輸入都不會。還好日本導航系統很完整，除了可以輸入電話之外，也可以使用日本獨有地圖資料系統 MapCode (マップコード)。</p><p><a href="https://www.mapion.co.jp/" target="_blank" rel="noopener">MapCode</a> 透過將地圖不斷細分劃格的方式，藉此標示出地點的詳細位置資訊，共由 9 ~ 10 個數字所組成。可以在導航前，事先在家裡在官網上輸入地址，查好景點的 Mapcode 。但是有用過的就會發現，日本的地址不太會打，外加輸入繁體字常常會搜尋不到，所以本文章使用大家熟悉的 google map 來做轉換。透過 google api 把地址轉換成經緯度，再利用爬蟲將經緯度轉換成 mapcode 。</p><hr><h2 id="功能說明"><a href="#功能說明" class="headerlink" title="功能說明"></a>功能說明</h2><h3 id="TransLatLng"><a href="#TransLatLng" class="headerlink" title="TransLatLng"></a><code>TransLatLng</code></h3><p>將查詢的地址轉換成經緯度，解碼器由 google 提供，如需大量使用請改使用<a href="https://developers.google.com/maps/documentation/javascript/get-api-key" target="_blank" rel="noopener">Google Maps API</a>，預設地址為<code>東京</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TransLatLng</span><span class="params">(self, query=<span class="string">'東京'</span>)</span>:</span></span><br><span class="line">    self.LocationParams = &#123;<span class="string">'address'</span>: query&#125;</span><br><span class="line">    r = requests.get(self.LocationURL, params = self.LocationParams)</span><br><span class="line">    responseJson = json.loads(r.text)</span><br><span class="line">    lat = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'geometry'</span>][<span class="string">'location'</span>][<span class="string">'lat'</span>]</span><br><span class="line">    lng = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'geometry'</span>][<span class="string">'location'</span>][<span class="string">'lng'</span>]</span><br><span class="line">    address = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'formatted_address'</span>]</span><br><span class="line">    <span class="keyword">return</span> [lat, lng, address]</span><br></pre></td></tr></table></figure><p>範例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mapcode</span><br><span class="line"></span><br><span class="line">example = mapcode.Mapcode()</span><br><span class="line"><span class="keyword">print</span> (example.TransLatLng(<span class="string">'福岡塔'</span>))</span><br></pre></td></tr></table></figure><p>輸出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># [緯度, 經度, 地址]</span></span><br><span class="line">[<span class="number">33.5932642</span>, <span class="number">130.3515144</span>, <span class="string">'2 Chome-3-２６ Momochihama, Sawara Ward, Fukuoka, Fukuoka Prefecture 814-0001, Japan'</span>]</span><br></pre></td></tr></table></figure><h3 id="TransMapcode"><a href="#TransMapcode" class="headerlink" title="TransMapcode"></a><code>TransMapcode</code></h3><p>將經緯度轉換成 mapcode</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">TransMapcode</span><span class="params">(self, lat, lon)</span>:</span></span><br><span class="line">    self.MapcodeParams = &#123;<span class="string">'address'</span>: <span class="string">''</span>, <span class="string">'lat'</span>: lat, <span class="string">'lon'</span> : lon, <span class="string">'scl'</span> : <span class="number">16</span>, <span class="string">'layer'</span> : <span class="string">''</span>&#125;</span><br><span class="line">    r = requests.get(self.MapcodeURL, params = self.MapcodeParams)</span><br><span class="line">    soup = BeautifulSoup(r.text, <span class="string">"html.parser"</span>)</span><br><span class="line">    mapcode = soup.find(<span class="string">'input'</span>, attrs=&#123;<span class="string">'id'</span>:<span class="string">'find'</span>, <span class="string">'name'</span>:<span class="string">'find'</span>, <span class="string">'type'</span>:<span class="string">'text'</span>&#125;)[<span class="string">'value'</span>]</span><br><span class="line">    <span class="keyword">return</span> mapcode</span><br></pre></td></tr></table></figure><p>範例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mapcode</span><br><span class="line"></span><br><span class="line">example = mapcode.Mapcode()</span><br><span class="line"><span class="keyword">print</span> (example.TransMapcode(<span class="number">33.5932642</span>, <span class="number">130.3515144</span>))</span><br></pre></td></tr></table></figure><p>輸出</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">13</span> <span class="number">312</span> <span class="number">703</span>*<span class="number">43</span></span><br></pre></td></tr></table></figure><hr><h2 id="完整程式碼"><a href="#完整程式碼" class="headerlink" title="完整程式碼"></a>完整程式碼</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Mapcode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.LocationParams = &#123;<span class="string">'address'</span>: <span class="string">'東京'</span>&#125;</span><br><span class="line">        self.LocationURL = <span class="string">'http://maps.googleapis.com/maps/api/geocode/json'</span></span><br><span class="line">        self.NameURL = <span class="string">'https://www.mapion.co.jp/m2/'</span></span><br><span class="line">        self.MapcodeParams = &#123;<span class="string">'address'</span>: <span class="string">'東京都文京区関口１丁目'</span>, <span class="string">'lat'</span>: <span class="string">'35.7090259'</span>, <span class="string">'lon'</span> : <span class="string">'139.7319925'</span>, <span class="string">'scl'</span> : <span class="number">16</span>, <span class="string">'layer'</span> : <span class="string">''</span>&#125;</span><br><span class="line">        self.MapcodeURL = <span class="string">'https://www.mapion.co.jp/f/mmail/send_mobile/SendMobile_map.html'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">TransLatLng</span><span class="params">(self, query=<span class="string">'東京'</span>)</span>:</span></span><br><span class="line">        self.LocationParams = &#123;<span class="string">'address'</span>: query&#125;</span><br><span class="line">        r = requests.get(self.LocationURL, params = self.LocationParams)</span><br><span class="line">        responseJson = json.loads(r.text)</span><br><span class="line">        lat = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'geometry'</span>][<span class="string">'location'</span>][<span class="string">'lat'</span>]</span><br><span class="line">        lng = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'geometry'</span>][<span class="string">'location'</span>][<span class="string">'lng'</span>]</span><br><span class="line">        address = responseJson.get(<span class="string">'results'</span>)[<span class="number">0</span>][<span class="string">'formatted_address'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># r = requests.get(self.NameURL + str(lat) + ',' + str(lng) + ',16')</span></span><br><span class="line">        <span class="comment"># soup = BeautifulSoup(r.text, "html.parser")</span></span><br><span class="line">        <span class="comment"># data = soup.find('meta', attrs=&#123;'name':'Keywords'&#125;)['content'].split(',')</span></span><br><span class="line">        <span class="comment"># address = data[0]</span></span><br><span class="line">        <span class="comment"># return [lat, lng, address, place]</span></span><br><span class="line">        <span class="keyword">return</span> [lat, lng, address]</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">TransMapcode</span><span class="params">(self, lat, lon)</span>:</span></span><br><span class="line">        self.MapcodeParams = &#123;<span class="string">'address'</span>: <span class="string">''</span>, <span class="string">'lat'</span>: lat, <span class="string">'lon'</span> : lon, <span class="string">'scl'</span> : <span class="number">16</span>, <span class="string">'layer'</span> : <span class="string">''</span>&#125;</span><br><span class="line">        r = requests.get(self.MapcodeURL, params = self.MapcodeParams)</span><br><span class="line">        soup = BeautifulSoup(r.text, <span class="string">"html.parser"</span>)</span><br><span class="line">        mapcode = soup.find(<span class="string">'input'</span>, attrs=&#123;<span class="string">'id'</span>:<span class="string">'find'</span>, <span class="string">'name'</span>:<span class="string">'find'</span>, <span class="string">'type'</span>:<span class="string">'text'</span>&#125;)[<span class="string">'value'</span>]</span><br><span class="line">        <span class="keyword">return</span> mapcode</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PYTHON </tag>
            
            <tag> MAPCODE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NFS 架設</title>
      <link href="2020/07/14/nfs/"/>
      <url>2020/07/14/nfs/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Network FileSystem (NFS) 稱為網路文件系統，是一種分佈式文件系統協定，允許在伺服器上安裝遠端目錄，讓使用者可以管理不同位置的儲存空間。</p><div class="note info">            <p>NFS Server 需要先查詢硬碟狀態，確認是可被掛載的，如果是新硬碟，可參考<a href="https://roychou121.github.io/2020/07/14/ubuntu-disk-partition/">此篇</a>設定。</p>          </div><hr><h2 id="NFS-Server"><a href="#NFS-Server" class="headerlink" title="NFS Server"></a>NFS Server</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>nfs-kernel-server：1.3.4</li></ul><h3 id="安裝-nfs-kernel-server"><a href="#安裝-nfs-kernel-server" class="headerlink" title="安裝 nfs-kernel-server"></a>安裝 <code>nfs-kernel-server</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nfs-kernel-server</span><br></pre></td></tr></table></figure><h3 id="修改-etc-hosts-deny-設定阻擋權限"><a href="#修改-etc-hosts-deny-設定阻擋權限" class="headerlink" title="修改 /etc/hosts.deny 設定阻擋權限"></a>修改 <code>/etc/hosts.deny</code> 設定阻擋權限</h3><p>下面範例是禁止任何主機能和你的 NFS 伺服器進行連接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts.deny</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">portmap:ALL </span><br><span class="line">lockd:ALL </span><br><span class="line">mountd:ALL</span><br><span class="line">rquotad:ALL </span><br><span class="line">statd:ALL</span><br></pre></td></tr></table></figure><h3 id="修改-etc-hosts-allow-設定允許權限"><a href="#修改-etc-hosts-allow-設定允許權限" class="headerlink" title="修改 /etc/hosts.allow 設定允許權限"></a>修改 <code>/etc/hosts.allow</code> 設定允許權限</h3><p>下面範例是允許 <code>192.168.0.*</code> 的主機和你的 NFS 伺服器建立連接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts.allow</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">portmap: 192.168.0.</span><br><span class="line">lockd: 192.168.0.</span><br><span class="line">rquotad: 192.168.0.</span><br><span class="line">mountd: 192.168.0.</span><br><span class="line">statd: 192.168.0.</span><br></pre></td></tr></table></figure><h3 id="修改-etc-exports-設定-NFS-掛載目錄及權限"><a href="#修改-etc-exports-設定-NFS-掛載目錄及權限" class="headerlink" title="修改 /etc/exports 設定 NFS 掛載目錄及權限"></a>修改 <code>/etc/exports</code> 設定 NFS 掛載目錄及權限</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/exports</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;raid 192.168.0.*(rw,sync,no_root_squash,no_subtree_check)</span><br></pre></td></tr></table></figure><ul><li><code>203.68.230.*</code> ：允許連線的IP， * 代表任意值</li><li><code>rw</code>：可讀寫</li><li><code>sync</code>：同步寫入記憶體和硬碟</li><li><code>no_root_squash</code>：用戶進入後即變為 root</li></ul><h3 id="更新並重啟-NFS-服務"><a href="#更新並重啟-NFS-服務" class="headerlink" title="更新並重啟 NFS 服務"></a>更新並重啟 NFS 服務</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo exportfs -arv</span><br><span class="line">sudo service nfs-kernel-server restart</span><br></pre></td></tr></table></figure><hr><h2 id="NFS-Client"><a href="#NFS-Client" class="headerlink" title="NFS Client"></a>NFS Client</h2><h3 id="系統環境-1"><a href="#系統環境-1" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>nfs-common：1.3.4</li></ul><h3 id="安裝-nfs-common"><a href="#安裝-nfs-common" class="headerlink" title="安裝 nfs-common"></a>安裝 <code>nfs-common</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nfs-common</span><br></pre></td></tr></table></figure><h3 id="建立資料夾"><a href="#建立資料夾" class="headerlink" title="建立資料夾"></a>建立資料夾</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /data</span><br></pre></td></tr></table></figure><h3 id="掛載-NFS-Server-的資料夾"><a href="#掛載-NFS-Server-的資料夾" class="headerlink" title="掛載 NFS Server 的資料夾"></a>掛載 NFS Server 的資料夾</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount 192.168.0.100:/raid /data</span><br></pre></td></tr></table></figure><ul><li><code>192.168.0.10</code> ：NFS Server 的 IP</li><li><code>/raid</code>：Server 的資料夾</li><li><code>/data</code>：Client 的資料夾</li></ul><h3 id="寫入-etc-fstab"><a href="#寫入-etc-fstab" class="headerlink" title="寫入 /etc/fstab"></a>寫入 <code>/etc/fstab</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.100:&#x2F;raid &#x2F;data nfs defaults 0 0</span><br></pre></td></tr></table></figure><h3 id="重啟掛載表"><a href="#重啟掛載表" class="headerlink" title="重啟掛載表"></a>重啟掛載表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -a</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NFS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 新增硬碟磁區</title>
      <link href="2020/07/14/ubuntu-disk-partition/"/>
      <url>2020/07/14/ubuntu-disk-partition/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Linux 中的 Parted 是一個用來管理磁碟分割區的工具，舉凡磁碟分割區的新增、刪除、大小變更等動作都可以用這個工具來處理。</p><div class="note warning">            <p><code>fdisk</code> 所能處理的磁碟容量上限是 2TB，若磁碟的容量大於 2TB 就無法使用。</p>          </div><hr><h2 id="操作步驟"><a href="#操作步驟" class="headerlink" title="操作步驟"></a>操作步驟</h2><p>一個完整從新硬碟到掛載磁區的步驟。</p><h3 id="安裝套件"><a href="#安裝套件" class="headerlink" title="安裝套件"></a>安裝套件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Ubuntu</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install parted</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> CentOS</span></span><br><span class="line">sudo yum install parted</span><br></pre></td></tr></table></figure><h3 id="進入-parted"><a href="#進入-parted" class="headerlink" title="進入 parted"></a>進入 <code>parted</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo parted</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/parted.PNG" class="" title="進入 parted"><h3 id="選擇硬碟"><a href="#選擇硬碟" class="headerlink" title="選擇硬碟"></a>選擇硬碟</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 假設硬碟代號為 sdb</span></span><br><span class="line">select /dev/sdb</span><br><span class="line">print</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/select.PNG" class="" title="選擇硬碟"><h3 id="建立磁碟分割表"><a href="#建立磁碟分割表" class="headerlink" title="建立磁碟分割表"></a>建立磁碟分割表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mklabel gpt</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/mklabel.PNG" class="" title="建立磁碟分割表"><h3 id="建立磁碟分割區"><a href="#建立磁碟分割區" class="headerlink" title="建立磁碟分割區"></a>建立磁碟分割區</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkpart</span><br><span class="line">print</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/mkpart.PNG" class="" title="建立磁碟分割區"><h3 id="離開-parted"><a href="#離開-parted" class="headerlink" title="離開 parted"></a>離開 <code>parted</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quit</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/quit.PNG" class="" title="離開 parted"><h3 id="格式化磁碟分割區"><a href="#格式化磁碟分割區" class="headerlink" title="格式化磁碟分割區"></a>格式化磁碟分割區</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install xfsprogs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 假設硬碟代號為 sdb，要格式化第一個磁區 sdb1</span></span><br><span class="line">sudo mkfs.xfs -f /dev/sdb1</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/mkfs.PNG" class="" title="格式化磁碟分割區"><h3 id="掛載磁碟分割區"><a href="#掛載磁碟分割區" class="headerlink" title="掛載磁碟分割區"></a>掛載磁碟分割區</h3><h4 id="查詢磁碟分割區-UUID"><a href="#查詢磁碟分割區-UUID" class="headerlink" title="查詢磁碟分割區 UUID"></a>查詢磁碟分割區 <code>UUID</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo blkid -s UUID</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/UUID.PNG" class="" title="查詢磁碟分割區"><h4 id="創建要掛載的資料夾"><a href="#創建要掛載的資料夾" class="headerlink" title="創建要掛載的資料夾"></a>創建要掛載的資料夾</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 假設資料夾為 data</span></span><br><span class="line">sudo mkdir /data</span><br></pre></td></tr></table></figure><h4 id="編輯-fstab"><a href="#編輯-fstab" class="headerlink" title="編輯 fstab"></a>編輯 <code>fstab</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/fstab</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># [Device] [Mount Point] [File System] [Options] [dump] [fsck order]</span><br><span class="line">&#x2F;dev&#x2F;disk&#x2F;by-uuid&#x2F;f6420c0d-b440-4d58-ba56-f4921d2221bb &#x2F;data xfs defaults 0 0</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/fstab.PNG" class="" title="編輯 fstab"><h4 id="重啟掛載表"><a href="#重啟掛載表" class="headerlink" title="重啟掛載表"></a>重啟掛載表</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -a</span><br></pre></td></tr></table></figure><h4 id="驗證是否掛載成功"><a href="#驗證是否掛載成功" class="headerlink" title="驗證是否掛載成功"></a>驗證是否掛載成功</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsblk</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/14/ubuntu-disk-partition/lsblk.PNG" class="" title="驗證是否掛載成功"><hr><h2 id="parted-其他常用指令"><a href="#parted-其他常用指令" class="headerlink" title="parted 其他常用指令"></a><code>parted</code> 其他常用指令</h2><h3 id="調整磁碟分割區大小"><a href="#調整磁碟分割區大小" class="headerlink" title="調整磁碟分割區大小"></a>調整磁碟分割區大小</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">resizepart</span><br></pre></td></tr></table></figure><h3 id="刪除磁碟分割區"><a href="#刪除磁碟分割區" class="headerlink" title="刪除磁碟分割區"></a>刪除磁碟分割區</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 假設硬碟代號為 sda，要刪除第一個磁區 sda1</span></span><br><span class="line">select /dev/sda1</span><br><span class="line">rm 1</span><br></pre></td></tr></table></figure><h3 id="修復磁碟分割區"><a href="#修復磁碟分割區" class="headerlink" title="修復磁碟分割區"></a>修復磁碟分割區</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 假設硬碟代號為 sda，要修復第一個磁區 sda1</span></span><br><span class="line">select /dev/sda1</span><br><span class="line">rescue</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DISK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triton Inference Server 第一版介紹</title>
      <link href="2020/07/13/nvidia-triton-inference-server-v1/"/>
      <url>2020/07/13/nvidia-triton-inference-server-v1/</url>
      
        <content type="html"><![CDATA[<div class="note danger">            <p>2020/10/02 此版維護期限已到期，未來將不再更新，請轉至<a href="https://roychou121.github.io/2020/07/20/nvidia-triton-inference-server/">最新版</a>。</p>          </div><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本章為提供給還在使用舊版的人參考，關於此套件的詳細說明也可都在最新版中查看。</p><hr><h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>GPU Driver：450.51.05</li><li>Docker：19.03.5</li><li>Docker Image：nvcr.io/nvidia/tritonserver:20.07-v1-py3</li></ul><h3 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝-Docker"><a href="#安裝-Docker" class="headerlink" title="安裝 Docker"></a>安裝 Docker</h4><p>本篇是將系統架設在 Docker 上，可以參考此<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">文章</a> 將 Docker 環境建立起來。</p><h4 id="下載映像檔"><a href="#下載映像檔" class="headerlink" title="下載映像檔"></a>下載映像檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull nvcr.io/nvidia/tritonserver:20.07-v1-py3</span><br></pre></td></tr></table></figure><h3 id="運行步驟"><a href="#運行步驟" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/server.png" class="" title="Server 流程圖"><h4 id="模型轉換"><a href="#模型轉換" class="headerlink" title="模型轉換"></a>模型轉換</h4><p>系統支援的模型如下，如訓練時所使用的框架非下述所示，則需進行轉換。</p><ul><li>Tensorflow (graphdef, savedmodel)</li><li>TensorRT (plan)</li><li>ONNX (onnx)</li><li>PyTorch (pt)</li><li>Caffe2 (netdef)</li></ul><div class="note info">            <p>為了增加系統效能，建議模型都要過 TensorRT 編譯。</p>          </div><h4 id="建立模型庫"><a href="#建立模型庫" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>模型庫中保存著多個模型包。<br>每個模型包皆由版本及設定檔所組成，版本建議以自然數依序命名 (Ex. 1,2,3…)。</p><p>建立模型庫範例如下圖所示：<br>以此範例來說<br>模型庫為 <code>model-repository</code><br>模型庫中共存放了4個模型包 (<code>mnistTensorrt</code>, <code>mnist-tftrt</code>, <code>tensorflowGraphdef</code>, <code>tensorflowSavedmodel</code>)<br>其中以 <code>mnist-tftrt</code> 模型包為例，<code>mnist-tftrt</code> 為此模型的命名，資料夾中存放了版本 <code>1</code> 的模型及設定檔。</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/repository.png" class="" title="建立模型庫"><h4 id="編輯設定檔"><a href="#編輯設定檔" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><p>每個模型包皆須有設定檔，系統會根據設定檔來運行模型，最基本的設定檔由 5 大元素組成：模型名稱、模型框架、最大批次大小、輸入及輸出層的資訊、GPU 實例資訊。</p><p>更詳盡的參數說明可以參考<a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/model_configuration.html" target="_blank" rel="noopener">官方文件</a>。</p><p>編輯設定檔範例如下圖所示：</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/config.png" class="" title="編輯設定檔"><div class="note info">            <p>設定檔中的模型名稱需與資料夾的模型名稱一致。</p>          </div><div class="note info">            <p>最大批次大小為推論批次設定的最大值，不一定是實際推論批次大小。</p>          </div><h4 id="運行伺服器端"><a href="#運行伺服器端" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><p>在運行前需指定此服務要跑幾個 GPU、走哪些 Port 以及模型庫的路徑。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus &lt;GPU Number&gt; --name &lt;Conatainer Name&gt; --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p &lt;Host Port&gt;:8000 -p &lt;Host Port&gt;:8001 -p &lt;Host Port&gt;:8002 -v &lt;Model Repository Path&gt;:/models nvcr.io/nvidia/tritonserver:20.07-v1-py3 tritonserver --model-store=/models</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">sudo docker run -d --gpus all --name Triton_Server --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v /home/user/Documents/model-repository:/models nvcr.io/nvidia/tritonserver:20.07-v1-py3 tritonserver --model-store=/models</span><br></pre></td></tr></table></figure><div class="note info">            <p>Port 8000 為 HTTP 協定通道<br>Port 8001 為 GRPC 協定通道</p>          </div><h4 id="檢查系統狀態"><a href="#檢查系統狀態" class="headerlink" title="檢查系統狀態"></a>檢查系統狀態</h4><p>檢查系統是否正常的運行中：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v localhost:8000/api/status</span><br></pre></td></tr></table></figure><p>Triton 提供 Prometheus Metrics，內容主要為 GPU 狀態和請求統計資訊等：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v http://localhost:8002/metrics</span><br></pre></td></tr></table></figure><hr><h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><h3 id="系統環境-1"><a href="#系統環境-1" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>Docker：19.03.5</li><li>Docker Image：nvcr.io/nvidia/tritonserver:20.07-v1-py3-clientsdk</li></ul><h3 id="安裝步驟-1"><a href="#安裝步驟-1" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="安裝-Docker-1"><a href="#安裝-Docker-1" class="headerlink" title="安裝 Docker"></a>安裝 Docker</h4><p>本篇是將系統架設在 Docker 上，可以參考此<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">文章</a> 將 Docker 環境建立起來。</p><h4 id="下載映像檔-1"><a href="#下載映像檔-1" class="headerlink" title="下載映像檔"></a>下載映像檔</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull nvcr.io/nvidia/tritonserver:20.07-v1-py3-clientsdk</span><br></pre></td></tr></table></figure><h3 id="運行步驟-1"><a href="#運行步驟-1" class="headerlink" title="運行步驟"></a>運行步驟</h3><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/client.png" class="" title="Client 流程圖"><h4 id="串接設備"><a href="#串接設備" class="headerlink" title="串接設備"></a>串接設備</h4><p>目前主流要推論的資料為數據、影像、聲音以及文字，在跟 Server 端溝通之前，Client 端需先跟各設備進行串接。</p><p>如影像型推論，就需跟攝影機、機台、儲存設備、呈現平台…等串接。</p><h4 id="撰寫程式碼"><a href="#撰寫程式碼" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><p>Client 端程式碼撰寫主要分成三大部分，依序為</p><ul><li>前處理<br>此部分主要處裡的事項為資訊進模型前的所有處理，如影像解碼、維度轉換、訊號處理等等。</li><li>Client-Server 溝通<br>指定將推論的模型資訊，透過 HTTP 或 GRPC 跟 Server 溝通。<br>詳細的函數說明可以參考<a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client_example.html" target="_blank" rel="noopener">官方文件</a>或<a href="https://github.com/NVIDIA/triton-inference-server/tree/master/src/clients/python/examples" target="_blank" rel="noopener">官方範例</a>。</li><li>後處理<br>此部分主要處裡的事項為接到 Server 回傳來推論結果後的所有處理，如儲存檔案、訊息整理、結果呈現等等。</li></ul><div class="note info">            <p>前後處理會因不同的應用實例有所差異，此部分不是本章的重點。<br>本章將會著重在說明 Triton Client-Server 基本的溝通函數，其他更深入的函數將在日後介紹。</p>          </div><h4 id="運行客戶端"><a href="#運行客戶端" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>在運行前需確認 Server 的 IP、走的協定 (HTTP or GRPC) 以及讀取儲存資料的位置。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --name &lt;Container Name&gt; -v &lt;Data Path&gt;:/data nvcr.io/nvidia/tritonserver:20.07-v1-py3-clientsdk bash -c '&lt;Client Code&gt;'</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Example</span></span><br><span class="line">sudo docker run -d --name Triton_Client -v /home/user/Documents/data:/data nvcr.io/nvidia/tritonserver:20.07-v1-py3-clientsdk bash -c 'python /data/client.py'</span><br></pre></td></tr></table></figure><hr><h2 id="範例"><a href="#範例" class="headerlink" title="範例"></a>範例</h2><p>接下來將以大家耳熟能詳的 <a href="https://www.tensorflow.org/quantum/tutorials/mnist" target="_blank" rel="noopener">MNIST</a> 所訓練出的模型當作範例，由於訓練模型不是本篇的重點，可以直接下載訓練好的模型進行後續的練習。</p><h3 id="Server-1"><a href="#Server-1" class="headerlink" title="Server"></a>Server</h3><h4 id="訓練模型"><a href="#訓練模型" class="headerlink" title="訓練模型"></a>訓練模型</h4><p>此部分以 MNIST 資料集和簡單的 CNN 模型當作範例。<br>撰寫框架為 Kears，來源為<a href="https://www.tensorflow.org/datasets/keras_example" target="_blank" rel="noopener">官方範本</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.compat.v2 <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_datasets <span class="keyword">as</span> tfds</span><br><span class="line"></span><br><span class="line">tfds.disable_progress_bar()</span><br><span class="line">tf.enable_v2_behavior()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(ds_train, ds_test), ds_info = tfds.load(</span><br><span class="line">    <span class="string">'mnist'</span>,</span><br><span class="line">    split=[<span class="string">'train'</span>, <span class="string">'test'</span>],</span><br><span class="line">    shuffle_files=<span class="literal">True</span>,</span><br><span class="line">    as_supervised=<span class="literal">True</span>,</span><br><span class="line">    with_info=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_img</span><span class="params">(image, label)</span>:</span></span><br><span class="line">  <span class="string">"""Normalizes images: `uint8` -&gt; `float32`."""</span></span><br><span class="line">  <span class="keyword">return</span> tf.cast(image, tf.float32) / <span class="number">255.</span>, label</span><br><span class="line"></span><br><span class="line">ds_train = ds_train.map(</span><br><span class="line">    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)</span><br><span class="line">ds_train = ds_train.cache()</span><br><span class="line">ds_train = ds_train.shuffle(ds_info.splits[<span class="string">'train'</span>].num_examples)</span><br><span class="line">ds_train = ds_train.batch(<span class="number">128</span>)</span><br><span class="line">ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ds_test = ds_test.map(</span><br><span class="line">    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)</span><br><span class="line">ds_test = ds_test.batch(<span class="number">128</span>)</span><br><span class="line">ds_test = ds_test.cache()</span><br><span class="line">ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>,activation=<span class="string">'relu'</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'sparse_categorical_crossentropy'</span>,</span><br><span class="line">    optimizer=tf.keras.optimizers.Adam(<span class="number">0.001</span>),</span><br><span class="line">    metrics=[<span class="string">'accuracy'</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.fit(</span><br><span class="line">    ds_train,</span><br><span class="line">    epochs=<span class="number">6</span>,</span><br><span class="line">    validation_data=ds_test,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 模型儲存</span></span><br><span class="line">model.save(<span class="string">'mnist'</span>)</span><br></pre></td></tr></table></figure><h4 id="模型轉換-1"><a href="#模型轉換-1" class="headerlink" title="模型轉換"></a>模型轉換</h4><p>由於儲存的模型已是 SavedModel 格式，所以此步只需用 TensorRT 編譯優化即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.compiler.tensorrt <span class="keyword">import</span> trt_convert <span class="keyword">as</span> trt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS</span><br><span class="line">conversion_params = conversion_params._replace(max_workspace_size_bytes=(<span class="number">1</span>&lt;&lt;<span class="number">32</span>))</span><br><span class="line">conversion_params = conversion_params._replace(precision_mode=<span class="string">"FP16"</span>)</span><br><span class="line">conversion_params = conversion_params._replace(maximum_cached_engines=<span class="number">128</span>)</span><br><span class="line">conversion_params = conversion_params._replace(use_calibration=<span class="literal">False</span>)</span><br><span class="line">conversion_params = conversion_params._replace(max_batch_size=<span class="number">32</span>)</span><br><span class="line">converter = trt.TrtGraphConverterV2(input_saved_model_dir=<span class="string">'mnist'</span>, conversion_params=conversion_params)</span><br><span class="line">converter.convert()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">yield</span> [tf.random.normal((<span class="number">32</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))]</span><br><span class="line">converter.build(input_fn)</span><br><span class="line">converter.save(<span class="string">'model.savedmodel'</span>)</span><br></pre></td></tr></table></figure><h4 id="建立模型庫-1"><a href="#建立模型庫-1" class="headerlink" title="建立模型庫"></a>建立模型庫</h4><p>以上面的模型為例，建立出的模型庫如下圖所示。</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/repository_ex.PNG" class="" title="建立模型庫"><h4 id="編輯設定檔-1"><a href="#編輯設定檔-1" class="headerlink" title="編輯設定檔"></a>編輯設定檔</h4><p>以下的參數為必要欄位，其他深入或客製化的參數，可以參考<a href="https://docs.nvidia.com/deeplearning/triton-inference-server/master-user-guide/docs/model_configuration.html" target="_blank" rel="noopener">官網文件</a>。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">name: <span class="string">"mnist"</span></span><br><span class="line">platform: <span class="string">"tensorflow_savedmodel"</span></span><br><span class="line">max_batch_size: <span class="number">32</span></span><br><span class="line">input [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"flatten_input"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        format: FORMAT_NHWC</span><br><span class="line">        dims: [<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">output [</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">"dense_1"</span></span><br><span class="line">        data_type: TYPE_FP32</span><br><span class="line">        dims: [<span class="number">10</span>]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">instance_group [</span><br><span class="line">    &#123;</span><br><span class="line">        kind: KIND_GPU</span><br><span class="line">        count: <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h4 id="運行伺服器端-1"><a href="#運行伺服器端-1" class="headerlink" title="運行伺服器端"></a>運行伺服器端</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -d --gpus all --name Triton_Server --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v /home/user/Documents/model-repository:/models nvcr.io/nvidia/tritonserver:20.06-py3 tritonserver --model-store=/models</span><br></pre></td></tr></table></figure><p>運行伺服器端後，成功的畫面如下所示。</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/runServer.PNG" class="" title="運行伺服器端成功畫面"><h3 id="Cleint"><a href="#Cleint" class="headerlink" title="Cleint"></a>Cleint</h3><h4 id="串接設備-1"><a href="#串接設備-1" class="headerlink" title="串接設備"></a>串接設備</h4><p>由於沒有實際的設備可以串接，此部分直接取用 MNIST 測試資料集中一張影像當作範例，最後將接到的推論結果直接顯示在螢幕上。</p><p>MNIST 測試資料如下圖所示。</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/input.jpg" class="" title="測試資料"><h4 id="撰寫程式碼-1"><a href="#撰寫程式碼-1" class="headerlink" title="撰寫程式碼"></a>撰寫程式碼</h4><figure class="highlight python"><figcaption><span>client.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tritongrpcclient</span><br><span class="line"><span class="keyword">from</span> tritonclientutils <span class="keyword">import</span> triton_to_np_dtype</span><br><span class="line"></span><br><span class="line"><span class="comment">## 前處理</span></span><br><span class="line">img = Image.open(<span class="string">'test.jpg'</span>).convert(<span class="string">'L'</span>)</span><br><span class="line">img = img.resize((<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">imgArr = np.asarray(img)/<span class="number">255</span></span><br><span class="line">imgArr = np.expand_dims(imgArr[:, :, np.newaxis], <span class="number">0</span>)</span><br><span class="line">imgArr= imgArr.astype(triton_to_np_dtype(<span class="string">'FP32'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## Client-Server 溝通</span></span><br><span class="line">protocol = ProtocolType.from_str(<span class="string">"gRPC"</span>)</span><br><span class="line">ctx = InferContext(url=<span class="string">'localhost:8001'</span>, protocol, <span class="string">'mnist'</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">responses = []</span><br><span class="line">responses.append(ctx.run(</span><br><span class="line">    &#123;<span class="string">"flatten_input"</span>:[imgArr]&#125;,</span><br><span class="line">    &#123;<span class="string">"dense_1"</span>:InferContext.ResultFormat.RAW&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment">## 後處理</span></span><br><span class="line"><span class="keyword">print</span> (np.argmax(responses[<span class="number">0</span>].as_numpy(<span class="string">'dense_1'</span>)[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><h4 id="運行客戶端-1"><a href="#運行客戶端-1" class="headerlink" title="運行客戶端"></a>運行客戶端</h4><p>將客戶端環境運行起來後，執行上部撰寫好的程式碼，即可進行推論。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --rm --name Triton_Client -v /home/user/data:/data nvcr.io/nvidia/tritonserver:20.07-v1-py3-clientsdk bash -c 'python /data/client.py'</span><br></pre></td></tr></table></figure><p>最後 MNIST 推論結果如下圖所示，可以發現有成功的預測出數字。</p><img src= "/img/loading.gif" data-src="/2020/07/13/nvidia-triton-inference-server-v1/result.PNG" class="" title="結果"><hr><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><ol><li><p><a href="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html" target="_blank" rel="noopener">Triton Inference Server Docs</a></p></li><li><p><a href="https://github.com/NVIDIA/triton-inference-server" target="_blank" rel="noopener">Triton Inference Server Github</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Inference </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
            <tag> INFERENCE </tag>
            
            <tag> SDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 安裝 Docker (支援 GPU)</title>
      <link href="2020/07/13/ubuntu-install-docker/"/>
      <url>2020/07/13/ubuntu-install-docker/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Docker 是一個開源專案，誕生於 2013 年初，最初是 dotCloud 公司內部的一個業餘專案。它基於 Google 公司推出的 Go 語言實作。 專案後來加入了 Linux 基金會，遵從了 Apache 2.0 協議，原始碼在 GitHub 上進行維護。</p><p>Docker 自開源後受到廣泛的關注和討論，以至於 dotCloud 公司後來都改名為 Docker Inc。Redhat 已經在其 RHEL6.5 中集中支援 Docker；Google 也在其 PaaS 產品中廣泛應用。</p><p>Docker 專案的目標是實作輕量級的作業系統虛擬化解決方案。 Docker 的基礎是 Linux 容器（LXC）等技術。</p><p>在 LXC 的基礎上 Docker 進行了進一步的封裝，讓使用者不需要去關心容器的管理，使得操作更為簡便。使用者操作 Docker 的容器就像操作一個快速輕量級的虛擬機一樣簡單。</p><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/docker.png" class="" title="Docker Docker 架構"><hr><h2 id="Docker-基本概念"><a href="#Docker-基本概念" class="headerlink" title="Docker 基本概念"></a>Docker 基本概念</h2><h3 id="映像檔-Image"><a href="#映像檔-Image" class="headerlink" title="映像檔 (Image)"></a>映像檔 (Image)</h3><ul><li>Docker 映像檔就是一個唯讀的模板。</li><li>映像檔可以用來建立 Docker 容器。</li><li>Docker 提供了一個很簡單的機制來建立映像檔或者更新現有的映像檔，使用者甚至可以直接從Docker Hub下載一個已經做好的映像檔來直接使用。</li></ul><h3 id="容器-Container"><a href="#容器-Container" class="headerlink" title="容器 (Container)"></a>容器 (Container)</h3><ul><li>容器是從映像檔建立的執行實例。它可以被啟動、開始、停止、刪除。每個容器都是相互隔離的、保證安全的平台。</li><li>可以把容器看做是一個簡易版的 Linux 環境（包括root使用者權限、程式空間、使用者空間和網路空間等）和在其中執行的應用程式。</li></ul><h3 id="倉庫-Repository"><a href="#倉庫-Repository" class="headerlink" title="倉庫 (Repository)"></a>倉庫 (Repository)</h3><ul><li>倉庫分為公開倉庫（Public）和私有倉庫（Private）兩種形式。</li><li>最大的公開倉庫是 <a href="https://hub.docker.com/" target="_blank" rel="noopener">Docker Hub</a>，存放了數量龐大的映像檔供使用者下載。</li><li>NVIDIA AI 倉庫為 <a href="https://ngc.nvidia.com" target="_blank" rel="noopener">NGC</a>，存放了 AI 常用框架的映像檔供使用者下載。</li></ul><hr><h2 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04</li><li>Docker：19.03</li><li>NVIDIA Container Toolkit：1.2.0</li></ul><h3 id="步驟"><a href="#步驟" class="headerlink" title="步驟"></a>步驟</h3><h4 id="安裝相依性套件"><a href="#安裝相依性套件" class="headerlink" title="安裝相依性套件"></a>安裝相依性套件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common</span><br></pre></td></tr></table></figure><h4 id="添加-Docker-GPG-key"><a href="#添加-Docker-GPG-key" class="headerlink" title="添加 Docker GPG key"></a>添加 Docker GPG key</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo apt-key fingerprint 0EBFCD88</span><br></pre></td></tr></table></figure><h4 id="添加-Docker-套件庫-穩定版"><a href="#添加-Docker-套件庫-穩定版" class="headerlink" title="添加 Docker 套件庫 (穩定版)"></a>添加 Docker 套件庫 (穩定版)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"</span><br></pre></td></tr></table></figure><h4 id="安裝-docker-ce-docker-ce-cli-containerd-io"><a href="#安裝-docker-ce-docker-ce-cli-containerd-io" class="headerlink" title="安裝 docker-ce docker-ce-cli containerd.io"></a>安裝 <code>docker-ce</code> <code>docker-ce-cli</code> <code>containerd.io</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><h4 id="添加-NVIDIA-Docker-套件庫"><a href="#添加-NVIDIA-Docker-套件庫" class="headerlink" title="添加 NVIDIA Docker 套件庫"></a>添加 NVIDIA Docker 套件庫</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br></pre></td></tr></table></figure><h4 id="安裝-NVIDIA-Container-Toolkit"><a href="#安裝-NVIDIA-Container-Toolkit" class="headerlink" title="安裝 NVIDIA Container Toolkit"></a>安裝 NVIDIA Container Toolkit</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nvidia-container-toolkit</span><br></pre></td></tr></table></figure><h4 id="重啟-Docker"><a href="#重啟-Docker" class="headerlink" title="重啟 Docker"></a>重啟 Docker</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h4 id="執行-Docker-不加-Sudo-選"><a href="#執行-Docker-不加-Sudo-選" class="headerlink" title="執行 Docker 不加 Sudo (選)"></a>執行 Docker 不加 Sudo (選)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo groupadd docker</span><br><span class="line">sudo gpasswd -a $&#123;USER&#125; docker</span><br><span class="line">sudo service docker restart</span><br></pre></td></tr></table></figure><hr><h2 id="Docker-基本操作"><a href="#Docker-基本操作" class="headerlink" title="Docker 基本操作"></a>Docker 基本操作</h2><h3 id="搜尋映像檔-search"><a href="#搜尋映像檔-search" class="headerlink" title="搜尋映像檔 search"></a>搜尋映像檔 <code>search</code></h3><p>在 Docker Hub 上尋找，會顯示熱度前幾名的映像檔。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker search &lt;Image Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/search.PNG" class="" title="Docker search 範例"><h3 id="取得映像檔-pull"><a href="#取得映像檔-pull" class="headerlink" title="取得映像檔 pull"></a>取得映像檔 <code>pull</code></h3><p>將映像檔從倉庫下載到本機。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull &lt;Image Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/pull.PNG" class="" title="Docker pull 範例"><h3 id="全部映像檔-images"><a href="#全部映像檔-images" class="headerlink" title="全部映像檔 images"></a>全部映像檔 <code>images</code></h3><p>顯示本機已下載的映像檔。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker images</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/images.PNG" class="" title="Docker images 範例"><h3 id="建立容器-run"><a href="#建立容器-run" class="headerlink" title="建立容器 run"></a>建立容器 <code>run</code></h3><p>建立容器並啟用。</p><table><thead><tr><th>Tag</th><th>Description</th></tr></thead><tbody><tr><td>-it</td><td>配置一個虛擬的終端機以及讓標準輸入維持在打開的狀態</td></tr><tr><td>-d</td><td>背景執行</td></tr><tr><td>–rm</td><td>Container 執行結束後自動刪除</td></tr><tr><td>–name <name></td><td>為 Container 命名</td></tr><tr><td>-p <host>:<container></td><td>將主機的 Port 綁定到 Container 的Port</td></tr><tr><td>-v <host>:<container></td><td>將主機的資料夾掛載到 Container 資料夾</td></tr><tr><td>–gpus ‘“device=<GPU ID>“‘</td><td>指定使用 GPU 編號</td></tr><tr><td>–gpus 2</td><td>指定使用前幾個 GPU</td></tr><tr><td>–gpus all</td><td>使用全部的 GPU</td></tr></tbody></table><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -it --name test --gpus all -p 20000:8888 -v /raid:/data nvcr.io/nvidia/tensorflow:20.06-tf2-py3 bash</span><br></pre></td></tr></table></figure><div class="note warning">            <p>可透過 <code>exit</code> 中回到本機系統，但第一次離開會停止容器的運行。</p>          </div><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/run.PNG" class="" title="Docker run 範例"><h3 id="全部容器-ps-a"><a href="#全部容器-ps-a" class="headerlink" title="全部容器 ps -a"></a>全部容器 <code>ps -a</code></h3><p>顯示本機已建立的容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker ps -a</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/ps.PNG" class="" title="顯示本機已建立的容器"><h3 id="進入運行中的容器"><a href="#進入運行中的容器" class="headerlink" title="進入運行中的容器"></a>進入運行中的容器</h3><h4 id="使用-exec"><a href="#使用-exec" class="headerlink" title="使用 exec"></a>使用 <code>exec</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker exec -it &lt;Container ID or Name&gt; bash</span><br></pre></td></tr></table></figure><div class="note info">            <p>執行 exit 時，不會中止容器。</p>          </div><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/exec.PNG" class="" title="進入運行中的容器"><h4 id="使用-attach"><a href="#使用-attach" class="headerlink" title="使用 attach"></a>使用 <code>attach</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker attach &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><div class="note info">            <p>執行 exit 時，就會中止容器。</p>          </div><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/attach.PNG" class="" title="進入運行中的容器"><h3 id="啟用容器-start"><a href="#啟用容器-start" class="headerlink" title="啟用容器 start"></a>啟用容器 <code>start</code></h3><p>啟動停止的容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker start &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/start.PNG" class="" title="啟動停止的容器"><h3 id="停止容器-stop"><a href="#停止容器-stop" class="headerlink" title="停止容器 stop"></a>停止容器 <code>stop</code></h3><p>停止啟用的容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker stop &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/stop.PNG" class="" title="停止啟用的容器"><h3 id="打包容器-commit"><a href="#打包容器-commit" class="headerlink" title="打包容器 commit"></a>打包容器 <code>commit</code></h3><p>將容器包成映像檔。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker commit &lt;Container ID or Name&gt; &lt;Image Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/commit.PNG" class="" title="將容器包成映像檔"><h3 id="打包映像檔-save"><a href="#打包映像檔-save" class="headerlink" title="打包映像檔 save"></a>打包映像檔 <code>save</code></h3><p>將映像檔打包成檔案。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker save -o &lt;File Name&gt;.tar &lt;Image Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/save.PNG" class="" title="將映像檔打包成檔案"><h3 id="載入映像檔-load"><a href="#載入映像檔-load" class="headerlink" title="載入映像檔 load"></a>載入映像檔 <code>load</code></h3><p>將打包的映像檔檔案載入本機。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker load -i &lt;File Name&gt;.tar</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/load.PNG" class="" title="將打包的映像檔檔案載入本機"><h3 id="刪除容器-rm"><a href="#刪除容器-rm" class="headerlink" title="刪除容器 rm"></a>刪除容器 <code>rm</code></h3><p>刪除容器，如容器還在運行，可加 <code>-f</code> ，強制刪除。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker rm &lt;Container ID or Name&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 強制刪除</span></span><br><span class="line">sudo docker rm -f &lt;Container ID or Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/rm.PNG" class="" title="刪除容器"><h3 id="刪除映像檔-rmi"><a href="#刪除映像檔-rmi" class="headerlink" title="刪除映像檔 rmi"></a>刪除映像檔 <code>rmi</code></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker rmi &lt;Image Name&gt;</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/13/ubuntu-install-docker/rmi.PNG" class="" title="刪除映像檔"><hr><h2 id="補充"><a href="#補充" class="headerlink" title="補充"></a>補充</h2><h3 id="安裝-nvidia-docker2"><a href="#安裝-nvidia-docker2" class="headerlink" title="安裝 nvidia-docker2"></a>安裝 <code>nvidia-docker2</code></h3><div class="note danger">            <p>Docker 版本小於 <code>19.03</code>，又要使用 GPU 了話，要改安裝 <code>nvidia-docker2</code>，不過此套件過一陣子將不再支援，不建議安裝。</p>          </div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 此範例 Docker 版本為 18.06</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install docker-ce=18.06.1~ce~3-0~ubuntu</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -</span><br><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y nvidia-docker2=2.0.3+docker18.06.1-1 nvidia-container-runtime=2.0.0+docker18.06.1-1</span><br><span class="line">sudo pkill -SIGHUP dockerd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DOCKER </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 安裝 Tensorflow 2.2</title>
      <link href="2020/07/12/ubuntu-install-tensorflow/"/>
      <url>2020/07/12/ubuntu-install-tensorflow/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前主流 AI 開發框架為 <a href="https://www.tensorflow.org/?hl=zh-tw" target="_blank" rel="noopener">Tensorflow</a> 及 <a href="https://pytorch.org/" target="_blank" rel="noopener">Pytorch</a>，本章將教學如何在系統上安裝 Tensorflow。</p><div class="note info">            <p>如要運行在 GPU 上，系統需先安裝好 GPU 驅動，未安裝可參考<a href="https://roychou121.github.io/2020/07/12/ubuntu-install-gpu-driver/">此篇</a>。</p>          </div><div class="note info">            <p>推薦使用 Docker 的環境進行 Tensorflow 的開發，可參考<a href="https://roychou121.github.io/2020/07/13/ubuntu-install-docker/">此篇</a>。</p>          </div><hr><h2 id="安裝"><a href="#安裝" class="headerlink" title="安裝"></a>安裝</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04 Desktop</li><li>GPU Driver：450.51.05</li><li>CUDA：10.2.89</li><li>cuDNN：8.0.0.180</li><li>Tensorflow：2.2</li></ul><h3 id="步驟"><a href="#步驟" class="headerlink" title="步驟"></a>步驟</h3><h4 id="安裝相依性套件"><a href="#安裝相依性套件" class="headerlink" title="安裝相依性套件"></a>安裝相依性套件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get update</span><br><span class="line">apt-get install wget gnupg2</span><br></pre></td></tr></table></figure><h4 id="添加-NVIDIA-套件庫"><a href="#添加-NVIDIA-套件庫" class="headerlink" title="添加 NVIDIA 套件庫"></a>添加 NVIDIA 套件庫</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.2.89-1_amd64.deb</span><br><span class="line">sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub</span><br><span class="line">sudo dpkg -i cuda-repo-ubuntu1804_10.2.89-1_amd64.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line">sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure><h4 id="安裝-CUDA-cuDNN"><a href="#安裝-CUDA-cuDNN" class="headerlink" title="安裝 CUDA cuDNN"></a>安裝 CUDA cuDNN</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install cuda-10-2 libcudnn8=8.0.0.180-1+cuda10.2 libcudnn8-dev=8.0.0.180-1+cuda10.2</span><br></pre></td></tr></table></figure><div class="note warning">            <p>此方法安裝 CUDA，將會自帶安裝 GPU 驅動。為避免蓋掉舊有的驅動，可從<a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="noopener">官網</a>下載 <code>run</code> 檔手動安裝(記得將安裝驅動的選項關掉)。</p>          </div><h4 id="手動安裝-CUDA-cuDNN-選"><a href="#手動安裝-CUDA-cuDNN-選" class="headerlink" title="手動安裝 CUDA cuDNN (選)"></a>手動安裝 CUDA cuDNN (選)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run</span><br><span class="line">sudo sh cuda_10.2.89_440.33.01_linux.run</span><br><span class="line">sudo apt-get install libcudnn8=8.0.0.180-1+cuda10.2 libcudnn8-dev=8.0.0.180-1+cuda10.2</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-tensorflow/cudarun.PNG" class="" title="記得關掉安裝 GPU 驅動"><h4 id="將-CUDA-加進環境變數-bashrc"><a href="#將-CUDA-加進環境變數-bashrc" class="headerlink" title="將 CUDA 加進環境變數 ~/.bashrc"></a>將 CUDA 加進環境變數 <code>~/.bashrc</code></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim ~/.bashrc</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><h4 id="激活環境變數"><a href="#激活環境變數" class="headerlink" title="激活環境變數"></a>激活環境變數</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h4 id="檢查-CUDA-是否安裝成功"><a href="#檢查-CUDA-是否安裝成功" class="headerlink" title="檢查 CUDA 是否安裝成功"></a>檢查 CUDA 是否安裝成功</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-tensorflow/cuda.PNG" class="" title="確認 CUDA 是否安裝成功"><h4 id="安裝-Tensorflow"><a href="#安裝-Tensorflow" class="headerlink" title="安裝 Tensorflow"></a>安裝 Tensorflow</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install python3-dev python3-pip</span><br><span class="line">pip3 install  tensorflow==2.2.0</span><br></pre></td></tr></table></figure><h4 id="檢查-Tensorflow-是否安裝成功"><a href="#檢查-Tensorflow-是否安裝成功" class="headerlink" title="檢查 Tensorflow 是否安裝成功"></a>檢查 Tensorflow 是否安裝成功</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -c "import tensorflow as tf; print(tf.__version__); print(tf.reduce_sum(tf.random.normal([1000, 1000])))"</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-tensorflow/tensorflow.PNG" class="" title="確認版本及可正常使用">]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Install </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> TENSORFLOW </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu 18.04 安裝 NVIDIA 顯示卡驅動</title>
      <link href="2020/07/12/ubuntu-install-gpu-driver/"/>
      <url>2020/07/12/ubuntu-install-gpu-driver/</url>
      
        <content type="html"><![CDATA[<div class="note info">            <p>2021/01/22 驅動版本更新至 v460.32.03</p>          </div><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>安裝驅動的方法很多種，可透過 <code>deb</code> 或是 <code>run</code> 檔等進行安裝，步驟大同小異。<br>其中如果作業系統為桌面版，在安裝 GPU 驅動時，會與預設顯示驅動衝突，造成顯示異常等狀況，所以本次教學將分成桌面及伺服器版兩個部分。</p><div class="note warning">            <p>如要安裝 CUDA ，要注意透過 <code>deb</code> 或是 <code>apt</code> 安裝，將會自帶安裝 GPU 驅動。為避免蓋掉舊有的驅動，可從<a href="https://developer.nvidia.com/cuda-toolkit" target="_blank" rel="noopener">官網</a>下載 <code>run</code> 檔手動安裝(記得將安裝驅動的選項關掉)。</p>          </div><hr><h2 id="桌面版"><a href="#桌面版" class="headerlink" title="桌面版"></a>桌面版</h2><h3 id="系統環境"><a href="#系統環境" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04 Desktop</li><li>GPU Driver：460.32.03</li></ul><h3 id="安裝步驟"><a href="#安裝步驟" class="headerlink" title="安裝步驟"></a>安裝步驟</h3><h4 id="下載驅動"><a href="#下載驅動" class="headerlink" title="下載驅動"></a>下載驅動</h4><p>請至<a href="https://www.nvidia.com.tw/Download/index.aspx?lang=tw" target="_blank" rel="noopener">NVIDIA 驅動程式下載</a>網站選擇型號、作業系統、CUDA版本、語言後即可下載。</p><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-gpu-driver/download.PNG" class="" title="下載驅動頁面範例"><p>或是透過指令下載</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install wget</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 418.152.00 (CUDA 10.1)</span></span><br><span class="line">wget http://us.download.nvidia.com/tesla/418.152.00/NVIDIA-Linux-x86_64-418.152.00.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 440.95.01 (CUDA 10.2)</span></span><br><span class="line">wget http://us.download.nvidia.com/tesla/440.95.01/NVIDIA-Linux-x86_64-440.95.01.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 450.102.04 (CUDA 11.0)</span></span><br><span class="line">wget https://us.download.nvidia.com/tesla/450.102.04/NVIDIA-Linux-x86_64-450.102.04.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 460.32.03 (CUDA 11.2)</span></span><br><span class="line">wget https://us.download.nvidia.com/tesla/460.32.03/NVIDIA-Linux-x86_64-460.32.03.run</span><br></pre></td></tr></table></figure><h4 id="移除舊有-GPU-驅動"><a href="#移除舊有-GPU-驅動" class="headerlink" title="移除舊有 GPU 驅動"></a>移除舊有 GPU 驅動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure><h4 id="查看-nouveau-是否正在執行"><a href="#查看-nouveau-是否正在執行" class="headerlink" title="查看 nouveau 是否正在執行"></a>查看 nouveau 是否正在執行</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure><p>如果有就要編輯 <code>/etc/modprobe.d/blacklist-nouveau.conf</code> 文件來禁止</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset&#x3D;0</span><br></pre></td></tr></table></figure><p>更新後重啟電腦</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h4 id="再次查看-nouveau-是否正在執行"><a href="#再次查看-nouveau-是否正在執行" class="headerlink" title="再次查看 nouveau 是否正在執行"></a>再次查看 nouveau 是否正在執行</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure><p>如果有就編輯 <code>/etc/modprobe.d/blacklist.conf</code> ，如果沒有就跳到下一步</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/modprobe.d/blacklist.conf</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">blacklist vga16fb</span><br><span class="line">blacklist nouveau</span><br><span class="line">blacklist rivafb</span><br><span class="line">blacklist rivatv</span><br><span class="line">blacklist nvidiafb</span><br></pre></td></tr></table></figure><p>再次更新後重啟電腦</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h4 id="安裝相依的軟體"><a href="#安裝相依的軟體" class="headerlink" title="安裝相依的軟體"></a>安裝相依的軟體</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install gcc make cmake dkms build-essential lib32ncurses5 lib32z1 lightdm</span><br></pre></td></tr></table></figure><h4 id="停用圖形化界面"><a href="#停用圖形化界面" class="headerlink" title="停用圖形化界面"></a>停用圖形化界面</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 方法1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 透過 Ctrl+Alt+F1 進入終端機界面</span></span><br><span class="line">sudo service lightdm stop</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 方法2</span></span><br><span class="line">sudo init 3</span><br></pre></td></tr></table></figure><h4 id="安裝驅動"><a href="#安裝驅動" class="headerlink" title="安裝驅動"></a>安裝驅動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bash NVIDIA-Linux-x86_64-460.32.03.run -no-opengl-files  -no-x-check -no-nouveau-check</span><br></pre></td></tr></table></figure><h4 id="啟動圖形化界面並重新啟動"><a href="#啟動圖形化界面並重新啟動" class="headerlink" title="啟動圖形化界面並重新啟動"></a>啟動圖形化界面並重新啟動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm start</span><br><span class="line">sudo update-initramfs -u</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h4 id="驗證安裝"><a href="#驗證安裝" class="headerlink" title="驗證安裝"></a>驗證安裝</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-gpu-driver/nvidiasmi.PNG" class="" title="GPU 相關資訊"><hr><h2 id="伺服器版"><a href="#伺服器版" class="headerlink" title="伺服器版"></a>伺服器版</h2><h3 id="系統環境-1"><a href="#系統環境-1" class="headerlink" title="系統環境"></a>系統環境</h3><ul><li>OS：Ubuntu 18.04 Server</li><li>GPU Driver：460.32.03</li></ul><h3 id="安裝方法一-run"><a href="#安裝方法一-run" class="headerlink" title="安裝方法一 run"></a>安裝方法一 <code>run</code></h3><h4 id="下載驅動-1"><a href="#下載驅動-1" class="headerlink" title="下載驅動"></a>下載驅動</h4><p>請至<a href="https://www.nvidia.com.tw/Download/index.aspx?lang=tw" target="_blank" rel="noopener">NVIDIA 驅動程式下載</a>網站選擇型號、作業系統、CUDA版本、語言後即可下載。</p><img src= "/img/loading.gif" data-src="/2020/07/12/ubuntu-install-gpu-driver/download.PNG" class="" title="下載驅動頁面範例"><p>或是透過指令下載</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install wget</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 418.152.00 (CUDA 10.1)</span></span><br><span class="line">wget http://us.download.nvidia.com/tesla/418.152.00/NVIDIA-Linux-x86_64-418.152.00.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 440.95.01 (CUDA 10.2)</span></span><br><span class="line">wget http://us.download.nvidia.com/tesla/440.95.01/NVIDIA-Linux-x86_64-440.95.01.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 450.102.04 (CUDA 11.0)</span></span><br><span class="line">wget https://us.download.nvidia.com/tesla/450.102.04/NVIDIA-Linux-x86_64-450.102.04.run</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 460.32.03 (CUDA 11.2)</span></span><br><span class="line">wget https://us.download.nvidia.com/tesla/460.32.03/NVIDIA-Linux-x86_64-460.32.03.run</span><br></pre></td></tr></table></figure><h4 id="移除舊有-GPU-驅動-1"><a href="#移除舊有-GPU-驅動-1" class="headerlink" title="移除舊有 GPU 驅動"></a>移除舊有 GPU 驅動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure><h4 id="安裝相依的軟體-1"><a href="#安裝相依的軟體-1" class="headerlink" title="安裝相依的軟體"></a>安裝相依的軟體</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install gcc make cmake dkms build-essential lib32ncurses5 lib32z1</span><br></pre></td></tr></table></figure><h4 id="安裝驅動-1"><a href="#安裝驅動-1" class="headerlink" title="安裝驅動"></a>安裝驅動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo bash NVIDIA-Linux-x86_64-460.32.03.run</span><br></pre></td></tr></table></figure><h4 id="重新啟動"><a href="#重新啟動" class="headerlink" title="重新啟動"></a>重新啟動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h4 id="驗證安裝-1"><a href="#驗證安裝-1" class="headerlink" title="驗證安裝"></a>驗證安裝</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><h3 id="安裝方法二-apt"><a href="#安裝方法二-apt" class="headerlink" title="安裝方法二 apt"></a>安裝方法二 <code>apt</code></h3><h4 id="安裝-GPU-驅動"><a href="#安裝-GPU-驅動" class="headerlink" title="安裝 GPU 驅動"></a>安裝 GPU 驅動</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nvidia-driver-460</span><br><span class="line"><span class="meta">#</span><span class="bash"> 不一定要裝</span></span><br><span class="line">sudo apt-get install mesa-common-dev freeglut3-dev</span><br></pre></td></tr></table></figure><h4 id="重啟系統"><a href="#重啟系統" class="headerlink" title="重啟系統"></a>重啟系統</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h4 id="驗證安裝-2"><a href="#驗證安裝-2" class="headerlink" title="驗證安裝"></a>驗證安裝</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><hr>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Install </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NVIDIA </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
